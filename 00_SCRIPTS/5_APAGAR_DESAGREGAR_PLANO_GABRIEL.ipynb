{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "950e6d4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Mapeamento de pastas concluído com sucesso!\n"
     ]
    }
   ],
   "source": [
    "# Importando bibliotecas\n",
    "from functions import *\n",
    "import pandas as pd\n",
    "import locale\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "import logging\n",
    "from openpyxl import load_workbook\n",
    "\n",
    "timer = Temporizador()\n",
    "timer.iniciar()\n",
    "\n",
    "locale.setlocale(locale.LC_TIME, 'Portuguese_Brazil.1252')  # Para Windows\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.float_format', '{:.2f}'.format)\n",
    "pd.set_option('display.expand_frame_repr', False)\n",
    "\n",
    "# Detecta se o script está sendo executado de um .py ou de um notebook\n",
    "try:\n",
    "    caminho_base = Path(__file__).resolve().parent\n",
    "except NameError:\n",
    "    # __file__ não existe em Jupyter ou ambiente interativo\n",
    "    caminho_base = Path.cwd()\n",
    "\n",
    "\n",
    "pasta_input_parquet = caminho_base.parent / '01_INPUT_PIPELINE/01_BD_PARQUET'\n",
    "pasta_staging_parquet = caminho_base.parent / '02_STAGING_PARQUET'\n",
    "pasta_painel = caminho_base.parent / '05_PAINEL'\n",
    "pasta_historico_planos = caminho_base.parent / '04_HISTORICO_PLANOS'\n",
    "\n",
    "print(\"✅ Mapeamento de pastas concluído com sucesso!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51809dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ler parquet df_vendas_krona\n",
    "df_vendas_krona = pd.read_parquet(pasta_staging_parquet / 'df_vendas_krona.parquet')\n",
    "\n",
    "# Filtrar df_vendas_krona ultimos 12 meses\n",
    "df_vendas_krona_12m = df_vendas_krona[df_vendas_krona['PERIODO'] >= (datetime.now() - pd.DateOffset(months=12))]\n",
    "\n",
    "# aGREGAR df_vendas_krona_12m por EMPRESA, COD_PROD, DESC_PRODUTO, FAMILIA, LINHA, REGIONAL_GESTOR, REGIONAL, PERIODO, SOMANDO QTD_VENDA E VOL_VENDA\n",
    "df_vendas_krona_12m_agrupado = df_vendas_krona_12m.groupby(['COD_PROD', 'DESC_PRODUTO', 'FAMILIA', 'LINHA', 'REGIONAL_GESTOR', 'REGIONAL']).agg({'QTD_VENDA': 'sum', 'VOL_VENDA': 'sum'}).reset_index()\n",
    "\n",
    "# Eliminar linhas com QTD_VENDA\n",
    "df_vendas_krona_12m_agrupado = df_vendas_krona_12m_agrupado[df_vendas_krona_12m_agrupado['QTD_VENDA'] > 0]\n",
    "\n",
    "# # Criar coluna divindo VOL_VENDA por QTD_VENDA, nome como PESO_UNIT\n",
    "df_vendas_krona_12m_agrupado['PESO_UNIT'] = df_vendas_krona_12m_agrupado['VOL_VENDA'] / df_vendas_krona_12m_agrupado['QTD_VENDA']\n",
    "\n",
    "# Criar DIM_PRODUTO com COD_PROD, DESC_PROD, PESO_UNIT\n",
    "df_dim_produto = (\n",
    "    df_vendas_krona_12m_agrupado\n",
    "    .drop_duplicates(subset=['COD_PROD'])\n",
    "    [['COD_PROD', 'DESC_PRODUTO', 'PESO_UNIT']]\n",
    "    .reset_index(drop=True)\n",
    ")            \n",
    "\n",
    "# # Remover colunas QTD_VENDA e PESO_UNIT do df_vendas_krona_12m_agrupado\n",
    "df_vendas_krona_12m_agrupado = df_vendas_krona_12m_agrupado.drop(columns=['QTD_VENDA', 'PESO_UNIT'])\n",
    "\n",
    "# Criar uma coluna TOTAL_VOL_VENDA, somando por REGIONAL_GESTOR, REGIONAL, FAMILIA\n",
    "df_vendas_krona_12m_agrupado['TOTAL_VOL_VENDA'] = df_vendas_krona_12m_agrupado.groupby(['REGIONAL_GESTOR', 'REGIONAL', 'FAMILIA'])['VOL_VENDA'].transform('sum')\n",
    "\n",
    "# Criar coluna PERC_PART, dividindo VOL_VENDA por TOTAL_VOL_VENDA\n",
    "df_vendas_krona_12m_agrupado['PERC_PART'] = df_vendas_krona_12m_agrupado['VOL_VENDA'] / df_vendas_krona_12m_agrupado['TOTAL_VOL_VENDA']\n",
    "\n",
    "# ler arquivo PLANO_REGIONAL.csv da pasta 04_HISTORICO_PLANOS\n",
    "df_plano_regional = pd.read_csv(\n",
    "    pasta_historico_planos / 'PLANO_REGIONAL.csv',\n",
    "    sep=';',\n",
    "    dtype=str,          # força tudo texto\n",
    "    encoding='latin1'   # evita dor de cabeça\n",
    ")\n",
    "\n",
    "df_plano_regional['VALOR'] = (\n",
    "    df_plano_regional['VALOR']\n",
    "    .str.replace('.', '', regex=False)   # se existir milhar\n",
    "    .str.replace(',', '.', regex=False)  # vírgula → ponto\n",
    "    .astype(float)\n",
    ")\n",
    "\n",
    "# Eliminar colunas ID, TIPO, ORIGEM_PLANO, VERSAO_PLANO\n",
    "df_plano_regional = df_plano_regional.drop(columns=['ID', 'TIPO', 'ORIGEM_PLANO', 'VERSAO_PLANO'])\n",
    "\n",
    "\n",
    "# Filtrar alguns dados para validar, como por exemplo, REGIONAL_GESTOR = 'CO NO' e FAMILIA = '00 - TUBOS PVC KRONA'\n",
    "df_plano_regional_filtrado = df_plano_regional[\n",
    "    (df_plano_regional['REGIONAL_GESTOR'] == 'CO NO') & \n",
    "    (df_plano_regional['REGIONAL'] == 'CENTRO OESTE') & \n",
    "    (df_plano_regional['FAMILIA'] == '00 - TUBOS PVC KRONA')\n",
    "]\n",
    "\n",
    "df_plano_explodido = df_plano_regional.merge(\n",
    "    df_vendas_krona_12m_agrupado[\n",
    "        ['COD_PROD', 'DESC_PRODUTO', 'FAMILIA', 'LINHA', \n",
    "         'REGIONAL_GESTOR', 'REGIONAL', 'PERC_PART']\n",
    "    ],\n",
    "    on=['REGIONAL_GESTOR', 'REGIONAL', 'FAMILIA'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "df_plano_explodido['KG_SKU'] = (\n",
    "    df_plano_explodido['VALOR'] *\n",
    "    df_plano_explodido['PERC_PART']\n",
    ")\n",
    "\n",
    "\n",
    "df_plano_explodido = df_plano_explodido.merge(\n",
    "    df_dim_produto[['COD_PROD', 'PESO_UNIT']],\n",
    "    on=['COD_PROD'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "\n",
    "df_plano_explodido['QTD_SKU'] = (\n",
    "    df_plano_explodido['KG_SKU'] /\n",
    "    df_plano_explodido['PESO_UNIT']\n",
    ")\n",
    "\n",
    "# Eliminar PERIODOS que a soma das linhas deles for 0\n",
    "periodos_com_soma_zero = df_plano_explodido.groupby('PERIODO')['KG_SKU'].sum()\n",
    "periodos_com_soma_zero = periodos_com_soma_zero[periodos_com_soma_zero == 0].index\n",
    "df_plano_explodido = df_plano_explodido[~df_plano_explodido['PERIODO'].isin(periodos_com_soma_zero)]\n",
    "\n",
    "# Salvar na minha DESKTOP um arquivo Excel com o nome PLANO_EXPLODIDO.xlsx, sem index, e com a formatação de número com vírgula e ponto decimal\n",
    "df_plano_explodido.to_excel(\n",
    "    r\"C:\\Users\\carlo\\OneDrive\\Desktop\\PLANO_EXPLODIDO.xlsx\",\n",
    "    index=False,\n",
    "    float_format=\"%.2f\"\n",
    ")\n",
    "\n",
    "# # Filtrar alguns dados para validar, como por exemplo, REGIONAL_GESTOR = 'CO NO' e FAMILIA = '00 - TUBOS PVC KRONA'\n",
    "# df_plano_explodido_filtrado = df_plano_explodido[\n",
    "#     (df_plano_explodido['REGIONAL_GESTOR'] == 'CO NO') & \n",
    "#     (df_plano_explodido['REGIONAL'] == 'CENTRO OESTE') & \n",
    "#     (df_plano_explodido['FAMILIA'] == '00 - TUBOS PVC KRONA') &\n",
    "#     (df_plano_explodido['COD_PROD'] == '0023') &\n",
    "#     (df_plano_explodido['PERIODO'] == '2026-03-01')\n",
    "# ].reset_index(drop=True)\n",
    "\n",
    "# df_plano_explodido_filtrado\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce86a48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb8ddd1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
