{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa7d6663",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Mapeamento de pastas concluÃ­do com sucesso!\n"
     ]
    }
   ],
   "source": [
    "# Importando bibliotecas\n",
    "from functions import *\n",
    "import pandas as pd\n",
    "import locale\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import duckdb\n",
    "import gc\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from prophet import Prophet\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import warnings\n",
    "import logging\n",
    "import shutil\n",
    "\n",
    "logging.basicConfig(level=logging.WARNING, format='%(message)s')\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "timer = Temporizador()\n",
    "timer.iniciar()\n",
    "\n",
    "locale.setlocale(locale.LC_TIME, 'Portuguese_Brazil.1252')  # Para Windows\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.float_format', '{:.2f}'.format)\n",
    "pd.set_option('display.expand_frame_repr', False)\n",
    "\n",
    "# Detecta se o script estÃ¡ sendo executado de um .py ou de um notebook\n",
    "try:\n",
    "    caminho_base = Path(__file__).resolve().parent\n",
    "except NameError:\n",
    "    # __file__ nÃ£o existe em Jupyter ou ambiente interativo\n",
    "    caminho_base = Path.cwd()\n",
    "\n",
    "pasta_input_parquet = caminho_base.parent / '01_INPUT_PIPELINE/01_BD_PARQUET'\n",
    "arquivo_input_regras_negocio = caminho_base.parent / '01_INPUT_PIPELINE/02_REGRAS_NEGOCIO/KRONA_REGRAS.xlsm'\n",
    "pasta_staging_parquet = caminho_base.parent / '02_STAGING_PARQUET' # Armazena arquivos parquet com tratamentos, aplicaÃ§Ãµes de regras, depara, etc\n",
    "pasta_input_painel = caminho_base.parent / '03_INPUT_PAINEL' # Armazena arquivos que serÃ£o consumidos no painel de S&OP para os gerentes\n",
    "pasta_painel = caminho_base.parent / '05_PAINEL'\n",
    "\n",
    "# Eliminar arquivos das pastas de 02_STAGING_PARQUET e 03_INPUT_PAINEL que serÃ£o regenerados\n",
    "pastas_para_limpar = [\n",
    "    pasta_staging_parquet,\n",
    "    pasta_input_painel,\n",
    "]\n",
    "\n",
    "for pasta in pastas_para_limpar:\n",
    "    if pasta.exists() and pasta.is_dir():\n",
    "        for item in pasta.iterdir():\n",
    "            if item.is_file() or item.is_symlink():\n",
    "                item.unlink()\n",
    "            elif item.is_dir():\n",
    "                shutil.rmtree(item)\n",
    "\n",
    "print(\"âœ… Mapeamento de pastas concluÃ­do com sucesso!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b167ce4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ImportaÃ§Ã£o e tratamento de dados do arquivo KRONA_REGRAS, concluÃ­dos com sucesso!\n"
     ]
    }
   ],
   "source": [
    "# Carregar dados arquivo KRONA_REGRAS\n",
    "caminho_arquivo = arquivo_input_regras_negocio\n",
    "\n",
    "#-----------------------------------------------------------------------#\n",
    "#--------------- Carregar produtos eliminar ----------------------------#\n",
    "#-----------------------------------------------------------------------#\n",
    "guia_excel = 'PRODUTOS_ELIMINAR'\n",
    "df_produtos_eliminar = pd.read_excel(caminho_arquivo, sheet_name=guia_excel, engine='calamine', dtype={'COD_PROD': str})\n",
    "df_produtos_eliminar['COD_PROD'] = df_produtos_eliminar['COD_PROD'].astype(str)\n",
    "df_produtos_eliminar = df_produtos_eliminar.drop_duplicates(subset=['COD_PROD'])\n",
    "df_produtos_eliminar = df_produtos_eliminar[df_produtos_eliminar['COD_PROD'].notna()].reset_index(drop=True)\n",
    "\n",
    "#-----------------------------------------------------------------------#\n",
    "#---------------Carregar Regionais Gestor ------------------------------#\n",
    "#-----------------------------------------------------------------------#\n",
    "guia_excel = 'REGIONAIS_GESTOR'\n",
    "df_regionais_gestor = pd.read_excel(caminho_arquivo, sheet_name=guia_excel, engine='calamine')\n",
    "df_regionais_gestor = df_regionais_gestor.drop_duplicates(subset=['REGIONAL', 'REGIONAL_GESTOR'])\n",
    "df_regionais_gestor = df_regionais_gestor[df_regionais_gestor['REGIONAL'].notna()].reset_index(drop=True)\n",
    "\n",
    "#-----------------------------------------------------------------------#\n",
    "#---------------Carrregar Demanda LanÃ§amento Novos Produtos ------------#\n",
    "#-----------------------------------------------------------------------#\n",
    "guia_excel = 'PRODUTOS_LANCAMENTOS'\n",
    "df_produtos_lancamento = pd.read_excel(caminho_arquivo, sheet_name=guia_excel, engine='calamine')\n",
    "# ðŸš¨ VALIDAR SE EXISTEM DADOS\n",
    "if df_produtos_lancamento.empty:\n",
    "    raise ValueError(\n",
    "        \"âŒ ERRO: Nenhuma informaÃ§Ã£o foi encontrada na aba PRODUTOS_LANCAMENTOS.\\n\"\n",
    "        \"âž¡ï¸ Verifique se a planilha possui dados vÃ¡lidos antes de executar o pipeline.\"\n",
    "    )\n",
    "df_produtos_lancamento['JANELA LANÃ‡AMENTO'] = df_produtos_lancamento['JANELA LANÃ‡AMENTO'].astype(str).str.strip()\n",
    "df_produtos_lancamento = df_produtos_lancamento[df_produtos_lancamento['JANELA LANÃ‡AMENTO'] != ''].reset_index(drop=True)\n",
    "df_produtos_lancamento.rename(columns={'COD': 'COD_PROD'}, inplace=True)\n",
    "df_produtos_lancamento = df_produtos_lancamento[df_produtos_lancamento['COD_PROD'].notna()].reset_index(drop=True)\n",
    "df_produtos_lancamento['COD_PROD'] = df_produtos_lancamento['COD_PROD'].astype(str)\n",
    "\n",
    "# Identifica colunas com datas vÃ¡lidas\n",
    "col_datas = []\n",
    "for col in df_produtos_lancamento.columns:\n",
    "    try:\n",
    "        pd.to_datetime(col, dayfirst=True, errors='raise')\n",
    "        col_datas.append(col)\n",
    "    except (ValueError, TypeError):\n",
    "        continue\n",
    "\n",
    "colunas_validas = ['COD_PROD'] + \\\n",
    "                    [col for col in df_produtos_lancamento.columns if 'CD:' in str(col)] + \\\n",
    "                    col_datas\n",
    "df_produtos_lancamento = df_produtos_lancamento[[col for col in colunas_validas if col in df_produtos_lancamento.columns]]\n",
    "\n",
    "# Transforma datas em linhas\n",
    "df_produtos_lancamento = df_produtos_lancamento.melt(\n",
    "    id_vars=[col for col in df_produtos_lancamento.columns if col not in col_datas],\n",
    "    value_vars=col_datas,\n",
    "    var_name='PERIODO',\n",
    "    value_name='VALOR'\n",
    ")\n",
    "df_produtos_lancamento = df_produtos_lancamento[df_produtos_lancamento['VALOR'].notna()].reset_index(drop=True)\n",
    "\n",
    "# Multiplica colunas CD pelo VALOR\n",
    "colunas_cd = [col for col in df_produtos_lancamento.columns if 'CD:' in str(col)]\n",
    "for col in colunas_cd:\n",
    "    df_produtos_lancamento[col] = df_produtos_lancamento[col] * df_produtos_lancamento['VALOR']\n",
    "df_produtos_lancamento.drop(columns=['VALOR'], inplace=True)\n",
    "\n",
    "# Transforma colunas CD em linhas\n",
    "df_produtos_lancamento = df_produtos_lancamento.melt(\n",
    "    id_vars=[col for col in df_produtos_lancamento.columns if col not in colunas_cd],\n",
    "    value_vars=colunas_cd,\n",
    "    var_name='CD',\n",
    "    value_name='QTD'\n",
    ")\n",
    "\n",
    "#-----------------------------------------------------------------------#\n",
    "#---------------Carregar Regionais Construtora -------------------------#\n",
    "#-----------------------------------------------------------------------#\n",
    "guia_excel = 'REGIONAIS_CONSTRUTORA'\n",
    "df_regionais_construtora = pd.read_excel(caminho_arquivo, sheet_name=guia_excel, engine='calamine')\n",
    "df_regionais_construtora = df_regionais_construtora.drop_duplicates(subset=['REGIONAL BASE', 'REGIONAL ATUALIZADA'])\n",
    "\n",
    "#-----------------------------------------------------------------------#\n",
    "#---------------Carregar Clientes para planejamento de Demanda----------#\n",
    "#-----------------------------------------------------------------------#\n",
    "guia_excel = 'CLIENTES_DEMANDA'\n",
    "df_clientes_plan_demanda = pd.read_excel(caminho_arquivo, sheet_name=guia_excel, engine='calamine', dtype={'Cod_Grupo_Cliente': str})\n",
    "df_clientes_plan_demanda = df_clientes_plan_demanda.drop_duplicates(subset=['Cod_Grupo_Cliente'])\n",
    "df_clientes_plan_demanda = df_clientes_plan_demanda[df_clientes_plan_demanda['Cod_Grupo_Cliente'].notna()].reset_index(drop=True)\n",
    "\n",
    "# Converter a coluna de clientes para set para acelerar o isin\n",
    "lista_clientes_plan_demanda = set(df_clientes_plan_demanda['Cod_Grupo_Cliente'])\n",
    "\n",
    "# Unir COD_PROD de df_produtos_lancamento e df_produtos_eliminar, formar uma unica lista de produtos a eliminar, e remover do df_fato_vendas_krona\n",
    "# produtos_a_eliminar = pd.concat([df_produtos_eliminar[['COD_PROD']], df_produtos_lancamento[['COD_PROD']]]).drop_duplicates().reset_index(drop=True)\n",
    "# FIXME: Retirei os produtos de lanÃ§amento da lista de exclusÃ£o conforme solicitaÃ§Ã£o da Anna no WORD\n",
    "produtos_a_eliminar = df_produtos_eliminar[['COD_PROD']].drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "#-----------------------------------------------------------------------#\n",
    "#---------------Carregar DIRECIONA_CLIENTES_REGIONAL--------------------#\n",
    "#-----------------------------------------------------------------------#\n",
    "guia_excel = 'DIRECIONA_CLIENTES_REGIONAL'\n",
    "df_direc_cli_regional = pd.read_excel(caminho_arquivo, sheet_name=guia_excel, engine='calamine', dtype={'COD_GRUPO_CLIENTE': str, 'COD_CLIENTE': str})\n",
    "df_direc_cli_regional = df_direc_cli_regional[df_direc_cli_regional['COD_CLIENTE'].notna()].reset_index(drop=True)\n",
    "\n",
    "print(\"âœ… ImportaÃ§Ã£o e tratamento de dados do arquivo KRONA_REGRAS, concluÃ­dos com sucesso!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54aed134",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Script para eliminar duplicaÃ§Ã£o de Chv_Cliente no Dim_Clientes_Krona, conforme orientado por Marcos TI, criamos essa rotina para encontrar as duplicaÃ§Ãµes, eliminar e gerar novo Parquet sem duplicaÃ§Ãµes.\n",
    "\n",
    "# Carregar o Parquet\n",
    "df_dim_cli_krona = pd.read_parquet(pasta_input_parquet / \"Dim_Clientes_Krona.parquet\")\n",
    "\n",
    "# Eliminar duplciaÃ§Ãµes mantendo a primeira ocorrÃªncia\n",
    "df_dim_cli_krona = df_dim_cli_krona.drop_duplicates(subset=[\"Chv_Cliente\"], keep='first').reset_index(drop=True)\n",
    "\n",
    "# Gerar novo Parquet sem duplicaÃ§Ãµes\n",
    "df_dim_cli_krona.to_parquet(pasta_input_parquet / \"Dim_Clientes_Krona.parquet\", index=False)\n",
    "\n",
    "del df_dim_cli_krona\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019d269e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # FIXME Cosulta para validaÃ§Ã£o de dados Anna, direto do parquet Fato_Vendas_Krona.parquet, sem relacionamentos, agrupando por Cod_Produto, criando coluna mes pela Dat_Entrega_Venda no formato AAAAMM, somando Qtd_Venda\n",
    "\n",
    "# fato_vendas = (pasta_input_parquet / \"Fato_Vendas_Krona.parquet\").as_posix()\n",
    "\n",
    "# query = f\"\"\"\n",
    "# WITH base AS (\n",
    "#   SELECT\n",
    "#     Cod_Produto,\n",
    "#     Qtd_Venda,\n",
    "#     CAST(Dat_Entrega_Venda AS VARCHAR) AS dt_str\n",
    "#   FROM parquet_scan('{fato_vendas}')\n",
    "#   WHERE TRY_CAST(NULLIF(TRIM(Cod_Bloqueio), '') AS INTEGER) IN (80,90,95,99)\n",
    "#     AND Cod_Empresa IN ('01','05','08','0802','10')\n",
    "# ),\n",
    "# parse AS (\n",
    "#   SELECT\n",
    "#     Cod_Produto,\n",
    "#     Qtd_Venda,\n",
    "#     COALESCE(\n",
    "#       TRY_STRPTIME(dt_str, '%Y-%m-%d'),\n",
    "#       TRY_STRPTIME(dt_str, '%Y-%m-%d %H:%M:%S'),\n",
    "#       TRY_STRPTIME(dt_str, '%d/%m/%Y'),\n",
    "#       TRY_STRPTIME(dt_str, '%d/%m/%Y %H:%M:%S'),\n",
    "#       TRY_STRPTIME(dt_str, '%Y%m%d')\n",
    "#     )::DATE AS dt\n",
    "#   FROM base\n",
    "# )\n",
    "# SELECT\n",
    "#   Cod_Produto,\n",
    "#   STRFTIME(dt, '%Y%m') AS Mes,\n",
    "#   SUM(Qtd_Venda) AS Qtd_Venda_Total\n",
    "# FROM parse\n",
    "# WHERE dt IS NOT NULL\n",
    "# GROUP BY\n",
    "#   Cod_Produto,\n",
    "#   Mes\n",
    "# ORDER BY\n",
    "#   Cod_Produto,\n",
    "#   Mes\n",
    "# \"\"\"\n",
    "\n",
    "\n",
    "# df_validacao_anna = duckdb.query(query).to_df()\n",
    "\n",
    "# # Gerar Excel para Anna\n",
    "# caminho_excel_saida = pasta_painel / f\"VALIDACAO_ANNA_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx\"\n",
    "# df_validacao_anna.to_excel(caminho_excel_saida, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8df03eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec151782390f4098ab2e28a7a9d59d5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Carregamento de dados concluÃ­do com sucesso!\n"
     ]
    }
   ],
   "source": [
    "# Where Des_Origem = 'Krona'\n",
    "#   And Cod_Empresa IN ('01','05','08','0802','10')\n",
    "#   And Dat_Emissao_Venda >=Â '01/01/2018';\n",
    "\n",
    "# Na dimensÃ£o de Produto tem o seguinte filtro:\n",
    "# Where Cod_Empresa IN ('01','05','08','0802','10')\n",
    "\n",
    "# Nos casos de pedidos cancelados, consideramos apenas o que foi realmente vendido ao cliente:\n",
    "# Se o pedido foi cancelado por completo, nÃ£o aparece nenhuma venda.\n",
    "# Se apenas uma parte foi cancelada, consideramos somente a parte que foi vendida.\n",
    "# AlÃ©m disso, tambÃ©m existem os bloqueios de pedidos, que representam a â€œetapaâ€ em que o pedido se encontra. Nesses casos, Ã© importante definir quais bloqueios devem ser considerados nessa anÃ¡lise.\n",
    "\n",
    "# falei com o AndrÃ© aqui pelo chat, e verificou comÂ aÂ Aline\n",
    "# a principio utiliza os cÃ³digos de bloqueio 80, 90Â ,Â 95Â eÂ 99\n",
    "\n",
    "# No arquivo parquet, precisamos filtrar o campo Des_Origem = \"Krona\". O motivo Ã© que existem pedidos faturados pelo Protheus que contam no resultado da Viqua, e este aplicativo \"CML - Vendas\" do Qlik Sense traz apenas os pedidos que geram resultadoÂ paraÂ aÂ Krona\n",
    "\n",
    "# Conslidando as informaÃ§Ãµes de fontes em Parquet\n",
    "empresa = 'Krona'\n",
    "fact = (pasta_input_parquet / \"Fato_Vendas_Krona.parquet\").as_posix()\n",
    "prod = (pasta_input_parquet / \"Dim_Produtos_Vendas_Krona.parquet\").as_posix()\n",
    "cli  = (pasta_input_parquet / \"Dim_Clientes_Krona.parquet\").as_posix()\n",
    "vend = (pasta_input_parquet / \"Dim_Vendedores_Krona.parquet\").as_posix()\n",
    "\n",
    "# Eliminar produtos das listas em Excel: PRODUTOS ELIMINAR e PRODUTOS LANÃ‡AMENTOS\n",
    "duckdb.register(\"elim\", produtos_a_eliminar[['COD_PROD']])\n",
    "\n",
    "sql = f\"\"\"\n",
    "WITH\n",
    "fato AS (\n",
    "  SELECT\n",
    "    Cod_Produto,\n",
    "    Chv_Cliente,\n",
    "    Chv_Vendedor,\n",
    "    DATE_TRUNC(\n",
    "      'month',\n",
    "      CAST(\n",
    "        COALESCE(\n",
    "          TRY_STRPTIME(TRIM(Dat_Entrega_Venda), '%Y-%m-%d'),\n",
    "          TRY_STRPTIME(TRIM(Dat_Entrega_Venda), '%d/%m/%Y')\n",
    "        ) AS DATE\n",
    "      )\n",
    "    ) AS PERIODO,\n",
    "    TRIM(Nom_Empresa) AS EMPRESA,\n",
    "    SUM(TRY_CAST(Qtd_Venda AS DOUBLE)) AS QTD_VENDA,\n",
    "    SUM(TRY_CAST(Qtd_Peso_Venda AS DOUBLE)) AS VOL_VENDA\n",
    "  FROM parquet_scan('{fact}')\n",
    "  WHERE UPPER(TRIM(Nom_Empresa)) LIKE '%{empresa.strip().upper()}%'\n",
    "    AND UPPER(TRIM(Des_Origem))  LIKE '%{empresa.strip().upper()}%'\n",
    "    AND Cod_Empresa IN ('01','05','08','0802','10')\n",
    "    AND TRY_CAST(NULLIF(TRIM(Cod_Bloqueio), '') AS INTEGER) IN (80,90,95,99)\n",
    "    AND TRY_CAST(Qtd_Venda AS DOUBLE) > 0\n",
    "    AND Dat_Entrega_Venda IS NOT NULL\n",
    "    AND TRIM(Dat_Entrega_Venda) <> ''\n",
    "    AND COALESCE(\n",
    "      TRY_STRPTIME(TRIM(Dat_Entrega_Venda), '%Y-%m-%d'),\n",
    "      TRY_STRPTIME(TRIM(Dat_Entrega_Venda), '%d/%m/%Y')\n",
    "    ) >= DATE '2022-01-01'\n",
    "  GROUP BY Cod_Produto, Chv_Cliente, Chv_Vendedor, PERIODO, EMPRESA\n",
    "),\n",
    "prod AS (\n",
    "  SELECT\n",
    "    Cod_Produto,\n",
    "    TRIM(Des_Produto) AS Des_Produto,\n",
    "    Cod_Familia,\n",
    "    TRIM(Des_Familia) AS Des_Familia,\n",
    "    Cod_Linha,\n",
    "    TRIM(Des_Linha) AS Des_Linha,\n",
    "    TRIM(Nom_Empresa) AS EMPRESA,\n",
    "    TRY_CAST(Num_Peso AS DOUBLE) AS PESO_UNIT\n",
    "  FROM parquet_scan('{prod}')\n",
    "  WHERE Des_Linha IS NOT NULL\n",
    "    AND TRIM(Des_Linha) <> ''\n",
    "    AND Cod_Empresa IN ('01','05','08','0802','10')\n",
    "),\n",
    "cli AS (\n",
    "  SELECT\n",
    "    Chv_Cliente,\n",
    "    TRIM(Nom_Cliente) AS NOME_CLIENTE,\n",
    "    TRIM(Nom_Empresa) AS EMPRESA,\n",
    "    Chv_Vendedor_Cliente,\n",
    "    TRIM(Des_Segmento) AS SEGMENTO,\n",
    "    -- Corrige COD_GRUPO_CLIENTE: se vazio, usa COD_CLIENTE\n",
    "    CASE\n",
    "      WHEN TRIM(Cod_Grupo_Cliente) = '' OR Cod_Grupo_Cliente IS NULL\n",
    "      THEN TRIM(SPLIT_PART(Chv_Cliente, '|', 2))\n",
    "      ELSE TRIM(Cod_Grupo_Cliente)\n",
    "    END AS COD_GRUPO_CLIENTE,\n",
    "    -- Corrige DESC_GRUPO_E_CLIENTE: se vazio, usa NOME_CLIENTE\n",
    "    CASE\n",
    "      WHEN TRIM(Des_Grupo_e_Cliente) = '' OR Des_Grupo_e_Cliente IS NULL\n",
    "      THEN TRIM(Nom_Cliente)\n",
    "      ELSE TRIM(Des_Grupo_e_Cliente)\n",
    "    END AS DESC_GRUPO_E_CLIENTE\n",
    "  FROM parquet_scan('{cli}')\n",
    "),\n",
    "vend AS (\n",
    "  SELECT\n",
    "    Chv_Vendedor,\n",
    "    TRIM(Des_Regiao) AS Des_Regiao\n",
    "  FROM parquet_scan('{vend}')\n",
    "),\n",
    "base AS (\n",
    "  SELECT f.*\n",
    "  FROM fato f\n",
    "  WHERE NOT EXISTS (\n",
    "    SELECT 1 FROM elim e WHERE e.COD_PROD = f.Cod_Produto\n",
    "  )\n",
    "),\n",
    "final AS (\n",
    "  SELECT\n",
    "    b.EMPRESA,\n",
    "    TRIM(SPLIT_PART(c.Chv_Cliente, '|', 2)) AS COD_CLIENTE,\n",
    "    c.NOME_CLIENTE,\n",
    "    c.COD_GRUPO_CLIENTE,\n",
    "    c.DESC_GRUPO_E_CLIENTE,\n",
    "    c.SEGMENTO,\n",
    "    b.Cod_Produto AS COD_PROD,\n",
    "    p.Des_Produto AS DESC_PRODUTO,\n",
    "    CAST(p.Cod_Familia AS VARCHAR) || ' - ' || p.Des_Familia AS FAMILIA,\n",
    "    CAST(p.Cod_Linha   AS VARCHAR) || ' - ' || p.Des_Linha   AS LINHA,\n",
    "    v1.Des_Regiao AS REGIAO_CLIENTE,\n",
    "    v2.Des_Regiao AS REGIAO_MOVIMENTO,\n",
    "    b.PERIODO,\n",
    "    b.QTD_VENDA,\n",
    "    b.VOL_VENDA,\n",
    "    b.VOL_VENDA / b.QTD_VENDA AS PESO_UNIT\n",
    "  FROM base b\n",
    "  LEFT JOIN prod p ON b.Cod_Produto = p.Cod_Produto AND b.EMPRESA = p.EMPRESA\n",
    "  LEFT JOIN cli  c ON b.Chv_Cliente = c.Chv_Cliente AND b.EMPRESA = c.EMPRESA\n",
    "  LEFT JOIN vend v1 ON c.Chv_Vendedor_Cliente = v1.Chv_Vendedor\n",
    "  LEFT JOIN vend v2 ON b.Chv_Vendedor         = v2.Chv_Vendedor\n",
    ")\n",
    "SELECT\n",
    "  UPPER(EMPRESA) AS EMPRESA,\n",
    "  COD_CLIENTE,\n",
    "  NOME_CLIENTE,\n",
    "  COD_GRUPO_CLIENTE,\n",
    "  DESC_GRUPO_E_CLIENTE,\n",
    "  SEGMENTO,\n",
    "  COD_PROD,\n",
    "  DESC_PRODUTO,\n",
    "  FAMILIA,\n",
    "  LINHA,\n",
    "  PESO_UNIT,\n",
    "  REGIAO_CLIENTE,\n",
    "  REGIAO_MOVIMENTO,\n",
    "  PERIODO,\n",
    "  QTD_VENDA,\n",
    "  VOL_VENDA\n",
    "FROM final\n",
    "\"\"\"\n",
    "df_vendas_krona = duckdb.query(sql).to_df()\n",
    "\n",
    "print(\"âœ… Carregamento de dados concluÃ­do com sucesso!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41f4d87e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "272a0e12458840748bcb0fc8c0758609",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… OrganizaÃ§Ã£o de Regionais e InserÃ§Ã£o de Regional Gestor concluÃ­dos com sucesso!\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 1. Criando coluna REGIONAL copiando a coluna REGIAO_CLIENTE \n",
    "#    no df_vendas_krona. \n",
    "#    Onde o segmento contÃ©m CONSTRUTORA ou INSTALADOR, buscar \n",
    "#    na tabela de regionais_construtora a regional atualizada.\n",
    "# ============================================================\n",
    "\n",
    "# Cria a tabela de de-para das regionais (jÃ¡ registrada no engine)\n",
    "duckdb.register(\"vendas\", df_vendas_krona)\n",
    "duckdb.register(\"map_reg\", df_regionais_construtora[['REGIONAL BASE','REGIONAL ATUALIZADA']])\n",
    "\n",
    "sql = \"\"\"\n",
    "WITH base AS (\n",
    "  SELECT\n",
    "    v.*,\n",
    "    -- Substitui valores vazios de REGIAO_CLIENTE por REGIAO_MOVIMENTO\n",
    "    COALESCE(NULLIF(v.REGIAO_CLIENTE,''), v.REGIAO_MOVIMENTO) AS RC_FIX,\n",
    "    UPPER(v.SEGMENTO) AS SEG_UP,\n",
    "    UPPER(v.REGIAO_CLIENTE) AS RC,\n",
    "    UPPER(v.REGIAO_MOVIMENTO) AS RM\n",
    "  FROM vendas v\n",
    "),\n",
    "\n",
    "ajuste AS (\n",
    "  SELECT\n",
    "    b.*,\n",
    "    CASE\n",
    "      -- 1) Se SEGMENTO contÃ©m CONSTRUTORA ou INSTALADOR => usa de-para\n",
    "      WHEN b.SEG_UP LIKE '%CONSTRUTORA%' OR b.SEG_UP LIKE '%INSTALADOR%'\n",
    "        THEN COALESCE(m.\"REGIONAL ATUALIZADA\", b.RC_FIX)\n",
    "      -- ============================================================\n",
    "      -- 2. Converter TELEVENDAS - Regras para definir REGIONAL:\n",
    "      --    REGIONAL = CONSTRUTORA => REGIONAL_CONSTRUTORA\n",
    "      --    REGIAO_CLIENTE = TELEVENDAS e REGIAO_MOVIMENTO = TELEVENDAS => TELEVENDAS\n",
    "      --    REGIAO_CLIENTE != TELEVENDAS e REGIAO_MOVIMENTO = TELEVENDAS => TELEVENDAS\n",
    "      --    REGIAO_CLIENTE = TELEVENDAS e REGIAO_MOVIMENTO != TELEVENDAS => REGIAO_MOVIMENTO\n",
    "      --    Caso contrÃ¡rio => REGIAO_CLIENTE\n",
    "      -- ============================================================\n",
    "      WHEN b.RC='TELEVENDAS' AND b.RM='TELEVENDAS' THEN 'TELEVENDAS'\n",
    "      WHEN b.RC<>'TELEVENDAS' AND b.RM='TELEVENDAS' THEN 'TELEVENDAS'\n",
    "      WHEN b.RC='TELEVENDAS' AND b.RM<>'TELEVENDAS' THEN b.RM\n",
    "      ELSE b.RC_FIX\n",
    "    END AS REGIONAL\n",
    "  FROM base b\n",
    "  LEFT JOIN map_reg m\n",
    "    ON m.\"REGIONAL BASE\" = b.REGIAO_CLIENTE\n",
    ")\n",
    "\n",
    "-- ============================================================\n",
    "-- Resultado final consolidado\n",
    "-- ============================================================\n",
    "SELECT\n",
    "  EMPRESA,\n",
    "  COD_CLIENTE,\n",
    "  NOME_CLIENTE,\n",
    "  COD_GRUPO_CLIENTE,\n",
    "  DESC_GRUPO_E_CLIENTE,\n",
    "  COD_PROD,\n",
    "  DESC_PRODUTO,\n",
    "  FAMILIA,\n",
    "  LINHA,\n",
    "  REGIONAL,\n",
    "  PERIODO,\n",
    "  SUM(QTD_VENDA) AS QTD_VENDA,\n",
    "  SUM(VOL_VENDA) AS VOL_VENDA\n",
    "FROM ajuste\n",
    "WHERE REGIONAL IS NOT NULL AND REGIONAL <> ''\n",
    "GROUP BY\n",
    "  EMPRESA,\n",
    "  COD_CLIENTE,\n",
    "  NOME_CLIENTE,\n",
    "  COD_GRUPO_CLIENTE,\n",
    "  DESC_GRUPO_E_CLIENTE,\n",
    "  COD_PROD,\n",
    "  DESC_PRODUTO,\n",
    "  FAMILIA,\n",
    "  LINHA,\n",
    "  REGIONAL,\n",
    "  PERIODO\n",
    "\"\"\"\n",
    "\n",
    "# Executa no DuckDB\n",
    "df_vendas_krona = duckdb.query(sql).to_df()\n",
    "\n",
    "# Inserir REGIONAL_GESTOR no df_vendas_krona\n",
    "df_vendas_krona = pd.merge(\n",
    "    df_vendas_krona,\n",
    "    df_regionais_gestor,\n",
    "    left_on='REGIONAL',\n",
    "    right_on='REGIONAL',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "colunas_ordenadas = [\n",
    "    \"EMPRESA\",\n",
    "    \"COD_CLIENTE\",\n",
    "    \"NOME_CLIENTE\",\n",
    "    \"COD_GRUPO_CLIENTE\",\n",
    "    \"DESC_GRUPO_E_CLIENTE\",\n",
    "    \"COD_PROD\",\n",
    "    \"DESC_PRODUTO\",\n",
    "    \"FAMILIA\",\n",
    "    \"LINHA\",\n",
    "    \"REGIONAL\",\n",
    "    \"REGIONAL_GESTOR\",\n",
    "    \"PERIODO\",\n",
    "    \"QTD_VENDA\",\n",
    "    \"VOL_VENDA\"\n",
    "]\n",
    "\n",
    "df_vendas_krona = df_vendas_krona[colunas_ordenadas]\n",
    "\n",
    "# FIXME Salvar df_vendas_krona em Parquet para salvar as alteraÃ§Ãµes, filtros e regras aplicadas no histÃ³rico, otimizando memÃ³ria e garantindo rastreabilidade\n",
    "df_vendas_krona.to_parquet(pasta_staging_parquet / \"df_vendas_krona.parquet\", index=False)\n",
    "\n",
    "print(\"âœ… OrganizaÃ§Ã£o de Regionais e InserÃ§Ã£o de Regional Gestor concluÃ­dos com sucesso!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd99a756",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ¦† ExportaÃ§Ã£o de Dados Vendas para Planejamento Colaborativo\n",
    "# ðŸŽ¯ Objetivo: Exportar CSV para o Plano Colaborativo\n",
    "df_vendas_krona['NIVEL_PLAN_DEMANDA'] = np.where(\n",
    "    df_vendas_krona['COD_GRUPO_CLIENTE'].isin(lista_clientes_plan_demanda),\n",
    "    'CLIENTE',\n",
    "    'PRODUTO'\n",
    ")\n",
    "\n",
    "# Separa os DataFrames\n",
    "df_hist_vend_PRODUTO = df_vendas_krona[df_vendas_krona['NIVEL_PLAN_DEMANDA'] == 'PRODUTO']\n",
    "df_hist_vend_CLIENTE = df_vendas_krona[df_vendas_krona['NIVEL_PLAN_DEMANDA'] == 'CLIENTE']\n",
    "\n",
    "# Eliminar coluna NIVEL_PLAN_DEMANDA\n",
    "df_hist_vend_PRODUTO = df_hist_vend_PRODUTO.drop(columns=['NIVEL_PLAN_DEMANDA'])\n",
    "df_hist_vend_CLIENTE = df_hist_vend_CLIENTE.drop(columns=['NIVEL_PLAN_DEMANDA'])\n",
    "\n",
    "# Agrupar df_hist_vend_PRODUTO por REGIONAL_GESTOR, FAMILIA, PERIODO, VOL_VENDA\n",
    "df_hist_vend_PRODUTO = df_hist_vend_PRODUTO.groupby(\n",
    "    ['REGIONAL_GESTOR', 'REGIONAL', 'FAMILIA', 'PERIODO'],\n",
    "    as_index=False\n",
    ").agg({'VOL_VENDA': 'sum'}).reset_index(drop=True)\n",
    "\n",
    "# Salva como CSV\n",
    "df_hist_vend_PRODUTO.to_csv(\n",
    "    pasta_input_painel / 'HIST_VENDA_KRONA_AGREGADO.csv',\n",
    "    sep=';',\n",
    "    encoding='utf-8-sig',\n",
    "    index=False,\n",
    "    decimal=',',\n",
    "    float_format=\"%.2f\"\n",
    ")\n",
    "\n",
    "# Agrupar df_hist_vend_CLIENTE por COD_GRUPO_CLIENTE, DESC_GRUPO_E_CLIENTE, REGIONAL_GESTOR, FAMILIA, PERIODO, VOL_VENDA\n",
    "df_hist_vend_CLIENTE = df_hist_vend_CLIENTE.groupby(\n",
    "    [\"COD_GRUPO_CLIENTE\",\"DESC_GRUPO_E_CLIENTE\", \"REGIONAL_GESTOR\", 'REGIONAL', \"FAMILIA\", \"PERIODO\"],\n",
    "    as_index=False\n",
    ").agg({'VOL_VENDA': 'sum'}).reset_index(drop=True)\n",
    "\n",
    "# Salva como CSV\n",
    "df_hist_vend_CLIENTE.to_csv(\n",
    "    pasta_input_painel / 'HIST_VENDA_KRONA_CLIENTE.csv',\n",
    "    sep=';',\n",
    "    encoding='utf-8-sig',\n",
    "    index=False,\n",
    "    decimal=',',\n",
    "    float_format=\"%.2f\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "edfb9c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerar os arquivos com mÃ©dia de vendas para Planejamento Colaborativo Agregado\n",
    "# Encontrar o primeiro dia do mÃªs atual\n",
    "\n",
    "colunas_agregadas = ['REGIONAL_GESTOR', 'REGIONAL', 'FAMILIA']\n",
    "\n",
    "hoje = datetime.today()\n",
    "primeiro_dia_mes_atual = datetime(hoje.year, hoje.month, 1)\n",
    "\n",
    "# Calcular o primeiro dia do mÃªs de 6 meses atrÃ¡s (excluindo mÃªs atual)\n",
    "primeiro_dia_6_meses_atras = (primeiro_dia_mes_atual - pd.DateOffset(months=6)).to_pydatetime()\n",
    "\n",
    "# Filtrar apenas os Ãºltimos 6 meses (excluindo mÃªs atual)\n",
    "mask = (df_hist_vend_PRODUTO['PERIODO'] >= primeiro_dia_6_meses_atras) & (df_hist_vend_PRODUTO['PERIODO'] < primeiro_dia_mes_atual)\n",
    "df_hist_vend_PRODUTO_ultimos_6_meses = df_hist_vend_PRODUTO.loc[mask].copy()\n",
    "\n",
    "# Ordenar por data crescente\n",
    "df_hist_vend_PRODUTO_ultimos_6_meses = df_hist_vend_PRODUTO_ultimos_6_meses.sort_values('PERIODO').reset_index(drop=True)\n",
    "\n",
    "# DataFrame dos 3 meses mais recentes (Ãºltimos 3 meses do intervalo filtrado)\n",
    "df_3_meses_mais_recentes = df_hist_vend_PRODUTO_ultimos_6_meses.copy()\n",
    "\n",
    "# Identificar as 3 datas mais recentes (sem duplicar por linha)\n",
    "meses_recentes = sorted(df_3_meses_mais_recentes['PERIODO'].unique())[-3:]\n",
    "\n",
    "# Filtrar todas as linhas que pertencem a esses 3 meses\n",
    "df_3_meses_mais_recentes = df_3_meses_mais_recentes[df_3_meses_mais_recentes['PERIODO'].isin(meses_recentes)].copy()\n",
    "\n",
    "# Agrupa pelas colunas desejadas e calcula a mÃ©dia das colunas numÃ©ricas\n",
    "df_3_meses_mais_recentes_media = df_3_meses_mais_recentes.groupby(colunas_agregadas).mean(numeric_only=True).reset_index()\n",
    "\n",
    "# Adicionar coluna MEDIA informando 'MÃ‰DIA 3 MESES' na coluna\n",
    "df_3_meses_mais_recentes_media['MEDIA'] = 'MÃ‰DIA 3 MESES'\n",
    "\n",
    "# Agrupamento fazendo mÃ©dia dos 6 meses\n",
    "df_6_meses_mais_recentes_media = df_hist_vend_PRODUTO_ultimos_6_meses.copy()\n",
    "df_6_meses_mais_recentes_media = df_6_meses_mais_recentes_media.groupby(colunas_agregadas).mean(numeric_only=True).reset_index()\n",
    "\n",
    "# Adicionar coluna MEDIA informando 'MÃ‰DIA 6 MESES' na coluna\n",
    "df_6_meses_mais_recentes_media['MEDIA'] = 'MÃ‰DIA 6 MESES'\n",
    "\n",
    "# Concatenar os DataFrames\n",
    "df_media_vendas_PRODUTO = pd.concat([df_3_meses_mais_recentes_media, df_6_meses_mais_recentes_media], ignore_index=True)\n",
    "\n",
    "# Pivotar a coluna MEDIA\n",
    "df_media_vendas_PRODUTO = df_media_vendas_PRODUTO.pivot_table(\n",
    "    index=colunas_agregadas,\n",
    "    columns='MEDIA',\n",
    "    values='VOL_VENDA',\n",
    "    aggfunc='sum',\n",
    "    fill_value=0\n",
    ").reset_index()\n",
    "\n",
    "# Gerar o arquivo CSV\n",
    "df_media_vendas_PRODUTO.to_csv(\n",
    "    pasta_input_painel / 'MEDIA_VENDA_KRONA_AGREGADO.csv',\n",
    "    sep=';',\n",
    "    encoding='utf-8-sig',\n",
    "    index=False,\n",
    "    decimal=',',\n",
    "    float_format=\"%.2f\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7dfd335e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Bases de Vendas para Planejamento Colaborativo geradas com sucesso!\n"
     ]
    }
   ],
   "source": [
    "# Gerar os arquivos com mÃ©dia de vendas para Planejamento Colaborativo por Cliente\n",
    "# Encontrar o primeiro dia do mÃªs atual\n",
    "colunas_agrupadas = ['COD_GRUPO_CLIENTE', 'DESC_GRUPO_E_CLIENTE', 'REGIONAL_GESTOR', 'REGIONAL', 'FAMILIA']\n",
    "\n",
    "hoje = datetime.today()\n",
    "primeiro_dia_mes_atual = datetime(hoje.year, hoje.month, 1)\n",
    "\n",
    "# Calcular o primeiro dia do mÃªs de 6 meses atrÃ¡s (excluindo mÃªs atual)\n",
    "primeiro_dia_6_meses_atras = (primeiro_dia_mes_atual - pd.DateOffset(months=6)).to_pydatetime()\n",
    "\n",
    "# Filtrar apenas os Ãºltimos 6 meses (excluindo mÃªs atual)\n",
    "mask = (df_hist_vend_CLIENTE['PERIODO'] >= primeiro_dia_6_meses_atras) & (df_hist_vend_CLIENTE['PERIODO'] < primeiro_dia_mes_atual)\n",
    "df_hist_vend_CLIENTE_ultimos_6_meses = df_hist_vend_CLIENTE.loc[mask].copy()\n",
    "\n",
    "# Ordenar por data crescente\n",
    "df_hist_vend_CLIENTE_ultimos_6_meses = df_hist_vend_CLIENTE_ultimos_6_meses.sort_values('PERIODO').reset_index(drop=True)\n",
    "\n",
    "# DataFrame dos 3 meses mais recentes (Ãºltimos 3 meses do intervalo filtrado)\n",
    "df_3_meses_mais_recentes = df_hist_vend_CLIENTE_ultimos_6_meses.copy()\n",
    "\n",
    "# Identificar as 3 datas mais recentes (sem duplicar por linha)\n",
    "meses_recentes = sorted(df_3_meses_mais_recentes['PERIODO'].unique())[-3:]\n",
    "\n",
    "# Filtrar todas as linhas que pertencem a esses 3 meses\n",
    "df_3_meses_mais_recentes = df_3_meses_mais_recentes[df_3_meses_mais_recentes['PERIODO'].isin(meses_recentes)].copy()\n",
    "\n",
    "# Agrupa pelas colunas desejadas e calcula a mÃ©dia das colunas numÃ©ricas\n",
    "df_3_meses_mais_recentes_media = df_3_meses_mais_recentes.groupby(colunas_agrupadas).mean(numeric_only=True).reset_index()\n",
    "\n",
    "# Adicionar coluna MEDIA informando 'MÃ‰DIA 3 MESES' na coluna\n",
    "df_3_meses_mais_recentes_media['MEDIA'] = 'MÃ‰DIA 3 MESES'\n",
    "\n",
    "# Agrupamento fazendo mÃ©dia dos 6 meses\n",
    "df_6_meses_mais_recentes_media = df_hist_vend_CLIENTE_ultimos_6_meses.copy()\n",
    "df_6_meses_mais_recentes_media = df_6_meses_mais_recentes_media.groupby(colunas_agrupadas).mean(numeric_only=True).reset_index()\n",
    "\n",
    "# Adicionar coluna MEDIA informando 'MÃ‰DIA 6 MESES' na coluna\n",
    "df_6_meses_mais_recentes_media['MEDIA'] = 'MÃ‰DIA 6 MESES'\n",
    "\n",
    "# Concatenar os DataFrames\n",
    "df_media_vendas_PRODUTO = pd.concat([df_3_meses_mais_recentes_media, df_6_meses_mais_recentes_media], ignore_index=True)\n",
    "\n",
    "# Pivotar a coluna MEDIA\n",
    "df_media_vendas_PRODUTO = df_media_vendas_PRODUTO.pivot_table(\n",
    "    index=colunas_agrupadas,\n",
    "    columns='MEDIA',\n",
    "    values='VOL_VENDA',\n",
    "    aggfunc='sum',\n",
    "    fill_value=0\n",
    ").reset_index()\n",
    "\n",
    "\n",
    "# Gerar o arquivo CSV\n",
    "df_media_vendas_PRODUTO.to_csv(\n",
    "    pasta_input_painel / 'MEDIA_VENDA_KRONA_CLIENTE.csv',\n",
    "    sep=';',\n",
    "    encoding='utf-8-sig',\n",
    "    index=False,\n",
    "    decimal=',',\n",
    "    float_format=\"%.2f\"\n",
    ")\n",
    "\n",
    "# FIXME\n",
    "del df_hist_vend_PRODUTO, df_hist_vend_CLIENTE, df_vendas_krona, produtos_a_eliminar\n",
    "gc.collect()\n",
    "\n",
    "print(\"âœ… Bases de Vendas para Planejamento Colaborativo geradas com sucesso!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf44530",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nðŸ§© HistÃ³rico dos Modelos Testados no Projeto\\n--------------------------------------------\\n\\n1. MÃ©dia Simples / MÃ©dia 12M\\n   DescriÃ§Ã£o: cÃ¡lculo da mÃ©dia das vendas dos Ãºltimos 12 meses.\\n   Objetivo: criar um ponto de partida rÃ¡pido para testar estabilidade.\\n   Vantagem: extremamente leve e previsÃ­vel.\\n   LimitaÃ§Ã£o: ignora tendÃªncias (crescimento ou queda) e nÃ£o reage a sazonalidades.\\n\\n2. MÃ©dia MÃ³vel Ponderada\\n   DescriÃ§Ã£o: mÃ©dia dos Ãºltimos 12 meses com pesos maiores para os meses mais recentes.\\n   Objetivo: suavizar o histÃ³rico sem perder sensibilidade Ã  tendÃªncia recente.\\n   Vantagem: melhora ligeiramente a resposta a movimentos recentes.\\n   LimitaÃ§Ã£o: ainda nÃ£o reconhece padrÃµes anuais completos de sazonalidade.\\n\\n3. Sazonalidade Percentual HistÃ³rica\\n   DescriÃ§Ã£o: calculava a participaÃ§Ã£o mÃ©dia de cada mÃªs no total anual.\\n   Objetivo: reproduzir o comportamento sazonal real da empresa.\\n   Vantagem: respeita picos e vales mensais do Ãºltimo ano completo.\\n   LimitaÃ§Ã£o: dependente da qualidade do Ãºltimo ano â€” nÃ£o projeta volume total, apenas distribui.\\n\\n4. LightGBM\\n   DescriÃ§Ã£o: modelo de machine learning (boosting de Ã¡rvores) aplicado sobre variÃ¡veis sazonais (seno/cosseno dos meses).\\n   Objetivo: prever volumes mensais aprendendo padrÃµes nÃ£o lineares.\\n   Vantagem: aprendizado rÃ¡pido e robusto em bases amplas.\\n   LimitaÃ§Ã£o: exige ajuste fino e mais dados; em sÃ©ries curtas, tende a superajustar.\\n\\n5. RegressÃ£o Linear (nÃ­vel anual)\\n   DescriÃ§Ã£o: ajusta uma reta sobre as vendas anuais (y = aÂ·x + b).\\n   Objetivo: capturar tendÃªncias de crescimento ou queda sustentadas.\\n   Vantagem: intuitivo e fÃ¡cil de justificar visualmente.\\n   LimitaÃ§Ã£o: nÃ£o lida bem com oscilaÃ§Ãµes bruscas ou sÃ©ries curtas.\\n\\n6. Holt-Winters Aditivo\\n   DescriÃ§Ã£o: modelo clÃ¡ssico de sÃ©ries temporais com nÃ­vel, tendÃªncia e sazonalidade (additive trend + seasonal).\\n   Objetivo: gerar previsÃµes suaves mantendo padrÃ£o anual.\\n   Vantagem: reconhecido e equilibrado entre suavidade e tendÃªncia.\\n   LimitaÃ§Ã£o: pesado em grandes volumes e instÃ¡vel em sÃ©ries curtas.\\n\\n7. Ensemble EstatÃ­stico (fase intermediÃ¡ria)\\n   DescriÃ§Ã£o: combinaÃ§Ã£o ponderada de modelos simples (RegressÃ£o + MÃ©dia + SuavizaÃ§Ã£o).\\n   Objetivo: estabilizar volumes sem perder aparÃªncia estatÃ­stica.\\n   Vantagem: resultados consistentes e realistas.\\n   LimitaÃ§Ã£o: apresentava sempre o mesmo nome, sem variaÃ§Ã£o por empresa.\\n\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "ðŸ§© HistÃ³rico dos Modelos Testados no Projeto\n",
    "--------------------------------------------\n",
    "\n",
    "1. MÃ©dia Simples / MÃ©dia 12M\n",
    "   DescriÃ§Ã£o: cÃ¡lculo da mÃ©dia das vendas dos Ãºltimos 12 meses.\n",
    "   Objetivo: criar um ponto de partida rÃ¡pido para testar estabilidade.\n",
    "   Vantagem: extremamente leve e previsÃ­vel.\n",
    "   LimitaÃ§Ã£o: ignora tendÃªncias (crescimento ou queda) e nÃ£o reage a sazonalidades.\n",
    "\n",
    "2. MÃ©dia MÃ³vel Ponderada\n",
    "   DescriÃ§Ã£o: mÃ©dia dos Ãºltimos 12 meses com pesos maiores para os meses mais recentes.\n",
    "   Objetivo: suavizar o histÃ³rico sem perder sensibilidade Ã  tendÃªncia recente.\n",
    "   Vantagem: melhora ligeiramente a resposta a movimentos recentes.\n",
    "   LimitaÃ§Ã£o: ainda nÃ£o reconhece padrÃµes anuais completos de sazonalidade.\n",
    "\n",
    "3. Sazonalidade Percentual HistÃ³rica\n",
    "   DescriÃ§Ã£o: calculava a participaÃ§Ã£o mÃ©dia de cada mÃªs no total anual.\n",
    "   Objetivo: reproduzir o comportamento sazonal real da empresa.\n",
    "   Vantagem: respeita picos e vales mensais do Ãºltimo ano completo.\n",
    "   LimitaÃ§Ã£o: dependente da qualidade do Ãºltimo ano â€” nÃ£o projeta volume total, apenas distribui.\n",
    "\n",
    "4. LightGBM\n",
    "   DescriÃ§Ã£o: modelo de machine learning (boosting de Ã¡rvores) aplicado sobre variÃ¡veis sazonais (seno/cosseno dos meses).\n",
    "   Objetivo: prever volumes mensais aprendendo padrÃµes nÃ£o lineares.\n",
    "   Vantagem: aprendizado rÃ¡pido e robusto em bases amplas.\n",
    "   LimitaÃ§Ã£o: exige ajuste fino e mais dados; em sÃ©ries curtas, tende a superajustar.\n",
    "\n",
    "5. RegressÃ£o Linear (nÃ­vel anual)\n",
    "   DescriÃ§Ã£o: ajusta uma reta sobre as vendas anuais (y = aÂ·x + b).\n",
    "   Objetivo: capturar tendÃªncias de crescimento ou queda sustentadas.\n",
    "   Vantagem: intuitivo e fÃ¡cil de justificar visualmente.\n",
    "   LimitaÃ§Ã£o: nÃ£o lida bem com oscilaÃ§Ãµes bruscas ou sÃ©ries curtas.\n",
    "\n",
    "6. Holt-Winters Aditivo\n",
    "   DescriÃ§Ã£o: modelo clÃ¡ssico de sÃ©ries temporais com nÃ­vel, tendÃªncia e sazonalidade (additive trend + seasonal).\n",
    "   Objetivo: gerar previsÃµes suaves mantendo padrÃ£o anual.\n",
    "   Vantagem: reconhecido e equilibrado entre suavidade e tendÃªncia.\n",
    "   LimitaÃ§Ã£o: pesado em grandes volumes e instÃ¡vel em sÃ©ries curtas.\n",
    "\n",
    "7. Ensemble EstatÃ­stico (fase intermediÃ¡ria)\n",
    "   DescriÃ§Ã£o: combinaÃ§Ã£o ponderada de modelos simples (RegressÃ£o + MÃ©dia + SuavizaÃ§Ã£o).\n",
    "   Objetivo: estabilizar volumes sem perder aparÃªncia estatÃ­stica.\n",
    "   Vantagem: resultados consistentes e realistas.\n",
    "   LimitaÃ§Ã£o: apresentava sempre o mesmo nome, sem variaÃ§Ã£o por empresa.\n",
    "      \n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "ðŸ“Š Modelos de PrevisÃ£o Aplicados (VersÃ£o Final)\n",
    "\n",
    "Este script aplica cinco modelos distintos de previsÃ£o de sÃ©ries temporais, compara o desempenho com base no RMSE\n",
    "(Root Mean Squared Error) e seleciona automaticamente o mais assertivo para gerar a projeÃ§Ã£o final.\n",
    "\n",
    "Modelos utilizados:\n",
    "\n",
    "1. RegressÃ£o Linear\n",
    "   - Captura: tendÃªncias lineares de longo prazo.\n",
    "   - Uso: quando o histÃ³rico mostra crescimento ou queda estÃ¡vel.\n",
    "   - ForÃ§a: fÃ¡cil de justificar e visualizar; ideal para projeÃ§Ãµes simples e diretas.\n",
    "\n",
    "2. Holt-Winters (SuavizaÃ§Ã£o Exponencial com sazonalidade multiplicativa)\n",
    "   - Captura: padrÃµes sazonais e tendÃªncia, com maior peso para os dados mais recentes.\n",
    "   - Uso: quando hÃ¡ sazonalidade clara e variaÃ§Ãµes proporcionais ao volume.\n",
    "   - ForÃ§a: modelo clÃ¡ssico, confiÃ¡vel e com excelente desempenho em sÃ©ries temporais mensais.\n",
    "\n",
    "3. ARIMA (AutoRegressive Integrated Moving Average)\n",
    "   - Captura: dependÃªncia temporal e ruÃ­do estatÃ­stico, sem necessidade de sazonalidade explÃ­cita.\n",
    "   - Uso: quando hÃ¡ padrÃ£o autoregressivo e estabilidade sem sazonalidade forte.\n",
    "   - ForÃ§a: modelo estatÃ­stico robusto, ideal para sÃ©ries estacionÃ¡rias ou suavizadas.\n",
    "\n",
    "4. Random Forest Regressor com variÃ¡veis sazonais\n",
    "   - Captura: relaÃ§Ãµes nÃ£o lineares e interaÃ§Ãµes entre tempo, mÃªs e ano.\n",
    "   - Uso: quando hÃ¡ sazonalidade, mas o padrÃ£o nÃ£o Ã© linear nem estÃ¡vel.\n",
    "   - ForÃ§a: flexÃ­vel, adaptÃ¡vel e resistente a ruÃ­dos; Ã³timo para sÃ©ries com comportamento irregular.\n",
    "\n",
    "5. Prophet (Facebook) com sazonalidade anual\n",
    "   - Captura: tendÃªncia, sazonalidade e feriados (se configurado).\n",
    "   - Uso: quando hÃ¡ sazonalidade anual bem definida e histÃ³rico suficiente.\n",
    "   - ForÃ§a: fÃ¡cil de ajustar, escalÃ¡vel e excelente para previsÃµes com mÃºltiplos componentes.\n",
    "\n",
    "O modelo com menor RMSE nos Ãºltimos 12 meses Ã© selecionado automaticamente para gerar a previsÃ£o final,\n",
    "que Ã© incorporada Ã  coluna 'VOL_VENDA_REAL' junto ao histÃ³rico, com marcaÃ§Ã£o do modelo escolhido.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea423ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PrevisÃ£o EstatÃ­stica\n",
    "\n",
    "# Carregar df_vendas_krona_mes do parquet\n",
    "df_vendas_krona = pd.read_parquet(pasta_staging_parquet / \"df_vendas_krona.parquet\")\n",
    "\n",
    "# Agrupar df_vendas_krona_mes por PERIODO criando index da coluna PERIODO    \n",
    "df_vendas_krona_hist_mes = df_vendas_krona.groupby('PERIODO').agg({'VOL_VENDA': 'sum'}).reset_index()\n",
    "\n",
    "# Usar o DataFrame jÃ¡ existente\n",
    "df = df_vendas_krona_hist_mes.copy()\n",
    "df[\"PERIODO\"] = pd.to_datetime(df[\"PERIODO\"])\n",
    "df = df.sort_values(\"PERIODO\")\n",
    "df.set_index(\"PERIODO\", inplace=True)\n",
    "\n",
    "# ParÃ¢metro de inÃ­cio do histÃ³rico\n",
    "inicio_historico = pd.Timestamp(\"2022-01-01\")  # ajuste conforme necessÃ¡rio\n",
    "df = df[df.index >= inicio_historico]\n",
    "\n",
    "# Filtrar atÃ© o Ãºltimo mÃªs completo anterior Ã  data atual\n",
    "hoje = pd.Timestamp.today()\n",
    "ultimo_mes_completo = pd.Timestamp(hoje.year, hoje.month, 1) - pd.offsets.MonthBegin(1)\n",
    "df_hist = df[df.index <= ultimo_mes_completo]\n",
    "\n",
    "# ParÃ¢metros de previsÃ£o\n",
    "meses_previsao = 6\n",
    "\n",
    "# Calcular primeiro mÃªs de previsÃ£o: dois meses apÃ³s hoje, sempre no dia 1\n",
    "primeiro_mes_previsao = pd.Timestamp(hoje.year, hoje.month, 1) + pd.DateOffset(months=2)\n",
    "\n",
    "# Calcular Ãºltimo mÃªs da previsÃ£o\n",
    "ultimo_mes_previsao = primeiro_mes_previsao + pd.DateOffset(months=meses_previsao - 1)\n",
    "\n",
    "# Ajustar para sempre terminar em junho ou dezembro\n",
    "if ultimo_mes_previsao.month <= 6:\n",
    "    ultimo_mes_previsao = pd.Timestamp(ultimo_mes_previsao.year, 6, 1)\n",
    "else:\n",
    "    ultimo_mes_previsao = pd.Timestamp(ultimo_mes_previsao.year, 12, 1)\n",
    "\n",
    "# Gerar datas futuras mensais\n",
    "future_dates = pd.date_range(start=primeiro_mes_previsao, end=ultimo_mes_previsao, freq=\"MS\")\n",
    "\n",
    "# FunÃ§Ã£o para RMSE\n",
    "def calc_rmse(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "# Holt-Winters com sazonalidade multiplicativa\n",
    "hw_model = ExponentialSmoothing(df_hist[\"VOL_VENDA\"], seasonal=\"multiplicative\", seasonal_periods=12).fit()\n",
    "hw_forecast = hw_model.forecast(len(future_dates))\n",
    "\n",
    "# ARIMA\n",
    "arima_model = ARIMA(df_hist[\"VOL_VENDA\"], order=(1,1,1)).fit()\n",
    "arima_forecast = arima_model.forecast(len(future_dates))\n",
    "\n",
    "# RegressÃ£o Linear\n",
    "df_lr = df_hist.copy()\n",
    "df_lr[\"time\"] = np.arange(len(df_lr))\n",
    "X_lr = df_lr[[\"time\"]]\n",
    "y_lr = df_lr[\"VOL_VENDA\"]\n",
    "lr_model = LinearRegression().fit(X_lr, y_lr)\n",
    "X_future = pd.DataFrame({\"time\": np.arange(len(df_lr), len(df_lr) + len(future_dates))})\n",
    "lr_forecast = lr_model.predict(X_future)\n",
    "\n",
    "# Random Forest com features sazonais\n",
    "df_lr[\"mes\"] = df_lr.index.month\n",
    "df_lr[\"ano\"] = df_lr.index.year\n",
    "X_rf = df_lr[[\"time\", \"mes\", \"ano\"]]\n",
    "rf_model = RandomForestRegressor().fit(X_rf, y_lr)\n",
    "X_future_rf = pd.DataFrame({\n",
    "    \"time\": np.arange(len(df_lr), len(df_lr) + len(future_dates)),\n",
    "    \"mes\": future_dates.month,\n",
    "    \"ano\": future_dates.year\n",
    "})\n",
    "rf_forecast = rf_model.predict(X_future_rf)\n",
    "\n",
    "# Prophet com sazonalidade anual\n",
    "df_prophet = df_hist.reset_index().rename(columns={\"PERIODO\": \"ds\", \"VOL_VENDA\": \"y\"})\n",
    "prophet_model = Prophet(yearly_seasonality=True, weekly_seasonality=False, daily_seasonality=False)\n",
    "prophet_model.fit(df_prophet)\n",
    "future_df = pd.DataFrame({\"ds\": future_dates})\n",
    "prophet_forecast = prophet_model.predict(future_df)\n",
    "prophet_pred = prophet_forecast.set_index(\"ds\")[\"yhat\"].reindex(future_dates)\n",
    "\n",
    "# Comparar modelos com os Ãºltimos 12 meses reais\n",
    "val_real = df_hist[\"VOL_VENDA\"].tail(12)\n",
    "val_hw = hw_model.fittedvalues.tail(12)\n",
    "val_arima = arima_model.predict(start=len(df_hist)-12, end=len(df_hist)-1)\n",
    "val_lr = lr_model.predict(X_lr.tail(12))\n",
    "val_rf = rf_model.predict(X_rf.tail(12))\n",
    "val_prophet = prophet_model.predict(df_prophet.tail(12)).set_index(\"ds\")[\"yhat\"]\n",
    "\n",
    "rmse_scores = {\n",
    "    \"Holt-Winters\": calc_rmse(val_real, val_hw),\n",
    "    \"ARIMA\": calc_rmse(val_real, val_arima),\n",
    "    \"Linear Regression\": calc_rmse(val_real, val_lr),\n",
    "    \"Random Forest\": calc_rmse(val_real, val_rf),\n",
    "    \"Prophet\": calc_rmse(val_real, val_prophet)\n",
    "}\n",
    "\n",
    "# Escolher melhor modelo\n",
    "best_model = min(rmse_scores.items(), key=lambda x: x[1])[0]\n",
    "\n",
    "# Selecionar previsÃ£o do modelo vencedor\n",
    "if best_model == \"Holt-Winters\":\n",
    "    final_forecast = hw_forecast\n",
    "elif best_model == \"ARIMA\":\n",
    "    final_forecast = arima_forecast\n",
    "elif best_model == \"Linear Regression\":\n",
    "    final_forecast = lr_forecast\n",
    "elif best_model == \"Random Forest\":\n",
    "    final_forecast = rf_forecast\n",
    "else:\n",
    "    final_forecast = prophet_pred\n",
    "\n",
    "# Criar DataFrame com previsÃµes\n",
    "df_forecast_final = pd.DataFrame({\n",
    "    \"PERIODO\": future_dates,\n",
    "    \"VOL_VENDA_REAL\": final_forecast,\n",
    "    \"MODELO_ESCOLHIDO\": [best_model] * len(future_dates)\n",
    "})\n",
    "\n",
    "# HistÃ³rico sem modelo\n",
    "df_final = df_hist.reset_index().rename(columns={\"VOL_VENDA\": \"VOL_VENDA_REAL\"})\n",
    "df_final[\"MODELO_ESCOLHIDO\"] = np.nan\n",
    "\n",
    "# Concatenar tudo\n",
    "df_vendas_krona_forecast_mensal = pd.concat([df_final, df_forecast_final], ignore_index=True)\n",
    "\n",
    "# Salvar CSV\n",
    "# df_vendas_krona_forecast_mensal.to_csv(\n",
    "#     pasta_staging_parquet / \"df_vendas_krona_forecast_mensal.csv\",\n",
    "#     sep=';',\n",
    "#     encoding='utf-8-sig',\n",
    "#     index=False,\n",
    "#     decimal=',',\n",
    "#     float_format=\"%.2f\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "05ee0003",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PERIODO</th>\n",
       "      <th>VOL_VENDA_REAL</th>\n",
       "      <th>MODELO_ESCOLHIDO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>5927168.90</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-02-01</td>\n",
       "      <td>8077262.57</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-03-01</td>\n",
       "      <td>10952371.67</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-04-01</td>\n",
       "      <td>6694020.28</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-05-01</td>\n",
       "      <td>10330808.51</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2022-06-01</td>\n",
       "      <td>8979966.61</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2022-07-01</td>\n",
       "      <td>6847450.45</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2022-08-01</td>\n",
       "      <td>8874833.69</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2022-09-01</td>\n",
       "      <td>9977242.79</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2022-10-01</td>\n",
       "      <td>7662463.63</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2022-11-01</td>\n",
       "      <td>11145614.82</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2022-12-01</td>\n",
       "      <td>7248804.50</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>9089607.84</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2023-02-01</td>\n",
       "      <td>7756930.35</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2023-03-01</td>\n",
       "      <td>12567261.96</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2023-04-01</td>\n",
       "      <td>5957447.12</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2023-05-01</td>\n",
       "      <td>10423338.36</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2023-06-01</td>\n",
       "      <td>9595603.27</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2023-07-01</td>\n",
       "      <td>9108869.16</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2023-08-01</td>\n",
       "      <td>11966050.52</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2023-09-01</td>\n",
       "      <td>9931927.66</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2023-10-01</td>\n",
       "      <td>8489296.10</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2023-11-01</td>\n",
       "      <td>10177685.56</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2023-12-01</td>\n",
       "      <td>8704302.07</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>8385938.21</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2024-02-01</td>\n",
       "      <td>8066526.56</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2024-03-01</td>\n",
       "      <td>9545364.55</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2024-04-01</td>\n",
       "      <td>9887302.38</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2024-05-01</td>\n",
       "      <td>9972498.95</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2024-06-01</td>\n",
       "      <td>12513662.29</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2024-07-01</td>\n",
       "      <td>11153576.28</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2024-08-01</td>\n",
       "      <td>7592516.23</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2024-09-01</td>\n",
       "      <td>9261179.13</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2024-10-01</td>\n",
       "      <td>11404536.21</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2024-11-01</td>\n",
       "      <td>7639496.01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2024-12-01</td>\n",
       "      <td>7706398.47</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2025-01-01</td>\n",
       "      <td>10623178.87</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2025-02-01</td>\n",
       "      <td>6272343.99</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2025-03-01</td>\n",
       "      <td>8935442.12</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2025-04-01</td>\n",
       "      <td>8265783.78</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>2025-05-01</td>\n",
       "      <td>9929354.53</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>2025-06-01</td>\n",
       "      <td>13238781.91</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>2025-07-01</td>\n",
       "      <td>11208223.60</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>2025-08-01</td>\n",
       "      <td>8418155.36</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>2025-09-01</td>\n",
       "      <td>8494103.96</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>2025-10-01</td>\n",
       "      <td>10349595.35</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>2025-11-01</td>\n",
       "      <td>8862065.49</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>2025-12-01</td>\n",
       "      <td>2654209.01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>2026-03-01</td>\n",
       "      <td>5602209.89</td>\n",
       "      <td>Random Forest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>2026-04-01</td>\n",
       "      <td>5526091.81</td>\n",
       "      <td>Random Forest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>2026-05-01</td>\n",
       "      <td>6062344.14</td>\n",
       "      <td>Random Forest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>2026-06-01</td>\n",
       "      <td>6454080.10</td>\n",
       "      <td>Random Forest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>2026-07-01</td>\n",
       "      <td>6086372.24</td>\n",
       "      <td>Random Forest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>2026-08-01</td>\n",
       "      <td>5574707.91</td>\n",
       "      <td>Random Forest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>2026-09-01</td>\n",
       "      <td>5463667.62</td>\n",
       "      <td>Random Forest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>2026-10-01</td>\n",
       "      <td>5722643.19</td>\n",
       "      <td>Random Forest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>2026-11-01</td>\n",
       "      <td>5416417.04</td>\n",
       "      <td>Random Forest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>2026-12-01</td>\n",
       "      <td>5229664.63</td>\n",
       "      <td>Random Forest</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      PERIODO  VOL_VENDA_REAL MODELO_ESCOLHIDO\n",
       "0  2022-01-01      5927168.90              NaN\n",
       "1  2022-02-01      8077262.57              NaN\n",
       "2  2022-03-01     10952371.67              NaN\n",
       "3  2022-04-01      6694020.28              NaN\n",
       "4  2022-05-01     10330808.51              NaN\n",
       "5  2022-06-01      8979966.61              NaN\n",
       "6  2022-07-01      6847450.45              NaN\n",
       "7  2022-08-01      8874833.69              NaN\n",
       "8  2022-09-01      9977242.79              NaN\n",
       "9  2022-10-01      7662463.63              NaN\n",
       "10 2022-11-01     11145614.82              NaN\n",
       "11 2022-12-01      7248804.50              NaN\n",
       "12 2023-01-01      9089607.84              NaN\n",
       "13 2023-02-01      7756930.35              NaN\n",
       "14 2023-03-01     12567261.96              NaN\n",
       "15 2023-04-01      5957447.12              NaN\n",
       "16 2023-05-01     10423338.36              NaN\n",
       "17 2023-06-01      9595603.27              NaN\n",
       "18 2023-07-01      9108869.16              NaN\n",
       "19 2023-08-01     11966050.52              NaN\n",
       "20 2023-09-01      9931927.66              NaN\n",
       "21 2023-10-01      8489296.10              NaN\n",
       "22 2023-11-01     10177685.56              NaN\n",
       "23 2023-12-01      8704302.07              NaN\n",
       "24 2024-01-01      8385938.21              NaN\n",
       "25 2024-02-01      8066526.56              NaN\n",
       "26 2024-03-01      9545364.55              NaN\n",
       "27 2024-04-01      9887302.38              NaN\n",
       "28 2024-05-01      9972498.95              NaN\n",
       "29 2024-06-01     12513662.29              NaN\n",
       "30 2024-07-01     11153576.28              NaN\n",
       "31 2024-08-01      7592516.23              NaN\n",
       "32 2024-09-01      9261179.13              NaN\n",
       "33 2024-10-01     11404536.21              NaN\n",
       "34 2024-11-01      7639496.01              NaN\n",
       "35 2024-12-01      7706398.47              NaN\n",
       "36 2025-01-01     10623178.87              NaN\n",
       "37 2025-02-01      6272343.99              NaN\n",
       "38 2025-03-01      8935442.12              NaN\n",
       "39 2025-04-01      8265783.78              NaN\n",
       "40 2025-05-01      9929354.53              NaN\n",
       "41 2025-06-01     13238781.91              NaN\n",
       "42 2025-07-01     11208223.60              NaN\n",
       "43 2025-08-01      8418155.36              NaN\n",
       "44 2025-09-01      8494103.96              NaN\n",
       "45 2025-10-01     10349595.35              NaN\n",
       "46 2025-11-01      8862065.49              NaN\n",
       "47 2025-12-01      2654209.01              NaN\n",
       "48 2026-03-01      5602209.89    Random Forest\n",
       "49 2026-04-01      5526091.81    Random Forest\n",
       "50 2026-05-01      6062344.14    Random Forest\n",
       "51 2026-06-01      6454080.10    Random Forest\n",
       "52 2026-07-01      6086372.24    Random Forest\n",
       "53 2026-08-01      5574707.91    Random Forest\n",
       "54 2026-09-01      5463667.62    Random Forest\n",
       "55 2026-10-01      5722643.19    Random Forest\n",
       "56 2026-11-01      5416417.04    Random Forest\n",
       "57 2026-12-01      5229664.63    Random Forest"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_vendas_krona_forecast_mensal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "788c5ef3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ============================================================\n",
    "# DESAGREGAÃ‡ÃƒO INTELIGENTE BASEADA NO MIX DOS ÃšLTIMOS 6 MESES\n",
    "# ============================================================\n",
    "\n",
    "# 1) Definir data limite (6 meses atrÃ¡s do Ãºltimo mÃªs completo)\n",
    "data_limite = ultimo_mes_completo - pd.DateOffset(months=6)\n",
    "\n",
    "# 2) Filtrar histÃ³rico dos Ãºltimos 6 meses\n",
    "df_6m = df_vendas_krona[df_vendas_krona[\"PERIODO\"] > data_limite].copy()\n",
    "\n",
    "# 3) Somar volume por linha completa (todas as suas chaves originais)\n",
    "chaves = [\n",
    "    \"EMPRESA\",\n",
    "    \"COD_CLIENTE\",\n",
    "    \"NOME_CLIENTE\",\n",
    "    \"COD_GRUPO_CLIENTE\",\n",
    "    \"DESC_GRUPO_E_CLIENTE\",\n",
    "    \"COD_PROD\",\n",
    "    \"DESC_PRODUTO\",\n",
    "    \"FAMILIA\",\n",
    "    \"LINHA\",\n",
    "    \"REGIONAL\",\n",
    "    \"REGIONAL_GESTOR\"\n",
    "]\n",
    "\n",
    "df_mix = (\n",
    "    df_6m.groupby(chaves)[\"VOL_VENDA\"]\n",
    "    .sum()\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# 4) Total geral dos Ãºltimos 6 meses (somatÃ³rio de tudo)\n",
    "total_6m = df_mix[\"VOL_VENDA\"].sum()\n",
    "\n",
    "# 5) Criar PESO_MIX com base nos Ãºltimos 6 meses\n",
    "df_mix[\"PESO_MIX\"] = df_mix[\"VOL_VENDA\"] / total_6m\n",
    "\n",
    "# 6) Filtrar somente forecast futuro\n",
    "df_forecast_fut = df_vendas_krona_forecast_mensal[\n",
    "    df_vendas_krona_forecast_mensal[\"PERIODO\"] > ultimo_mes_completo\n",
    "].copy()\n",
    "\n",
    "# 7) Desagregar: multiplicar forecast mensal total pelo mix real\n",
    "df_forecast_desagregado = (\n",
    "    df_forecast_fut\n",
    "    .assign(key=1)\n",
    "    .merge(df_mix.assign(key=1), on=\"key\")\n",
    "    .drop(columns=\"key\")\n",
    ")\n",
    "\n",
    "df_forecast_desagregado[\"VOL_VENDA\"] = (\n",
    "    df_forecast_desagregado[\"VOL_VENDA_REAL\"] *\n",
    "    df_forecast_desagregado[\"PESO_MIX\"]\n",
    ")\n",
    "\n",
    "# 8) Selecionar colunas finais no mesmo layout do seu pipeline\n",
    "df_forecast_desagregado = df_forecast_desagregado[[\n",
    "    \"EMPRESA\",\n",
    "    \"COD_CLIENTE\",\n",
    "    \"NOME_CLIENTE\",\n",
    "    \"COD_GRUPO_CLIENTE\",\n",
    "    \"DESC_GRUPO_E_CLIENTE\",\n",
    "    \"COD_PROD\",\n",
    "    \"DESC_PRODUTO\",\n",
    "    \"FAMILIA\",\n",
    "    \"LINHA\",\n",
    "    \"REGIONAL\",\n",
    "    \"REGIONAL_GESTOR\",\n",
    "    \"PERIODO\",\n",
    "    \"VOL_VENDA\"\n",
    "]]\n",
    "\n",
    "# 9) Salvar\n",
    "df_forecast_desagregado.to_parquet(\n",
    "    pasta_staging_parquet / \"df_forecast_vendas_krona.parquet\",\n",
    "    index=False,\n",
    "    compression='snappy'\n",
    ")\n",
    "\n",
    "# FIXME\n",
    "del df_vendas_krona_hist_mes, df_final, df_forecast_final, df_lr, df_prophet, df_vendas_krona, df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a274c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Processamento EstatÃ­stico e Dados Forecast gerados com sucesso!\n"
     ]
    }
   ],
   "source": [
    "# Separar a df_forecast_vendas_krona em dois dataframes:\n",
    "# df_forecast_vendas_krona_CLIENTE: clientes que terÃ£o planejamento de demanda\n",
    "# df_forecast_vendas_krona_PRODUTO: produtos que terÃ£o planejamento de demanda\n",
    "\n",
    "df_forecast_vendas_krona = df_forecast_desagregado.copy()\n",
    "\n",
    "# Se lista_clientes_plan_demanda estiver vazio â†’ todos sÃ£o PRODUTO\n",
    "if lista_clientes_plan_demanda and len(lista_clientes_plan_demanda) > 0:\n",
    "    df_forecast_vendas_krona['NIVEL_PLAN_DEMANDA'] = np.where(\n",
    "        df_forecast_vendas_krona['COD_GRUPO_CLIENTE'].isin(lista_clientes_plan_demanda),\n",
    "        'CLIENTE',\n",
    "        'PRODUTO'\n",
    "    )\n",
    "else:\n",
    "    # Se nÃ£o existe cliente para plan. demanda â†’ tudo produto\n",
    "    df_forecast_vendas_krona['NIVEL_PLAN_DEMANDA'] = 'PRODUTO'\n",
    "\n",
    "\n",
    "# Separar os dataframes com cÃ³pia explÃ­cita\n",
    "df_forecast_vendas_krona_CLIENTE = df_forecast_vendas_krona[df_forecast_vendas_krona['NIVEL_PLAN_DEMANDA'] == 'CLIENTE'].copy()\n",
    "df_forecast_vendas_krona_PRODUTO = df_forecast_vendas_krona[df_forecast_vendas_krona['NIVEL_PLAN_DEMANDA'] == 'PRODUTO'].copy()\n",
    "\n",
    "# Eliminar coluna NIVEL_PLAN_DEMANDA\n",
    "df_forecast_vendas_krona_CLIENTE.drop(columns=['NIVEL_PLAN_DEMANDA'], inplace=True)\n",
    "df_forecast_vendas_krona_CLIENTE.reset_index(drop=True, inplace=True)\n",
    "df_forecast_vendas_krona_PRODUTO.drop(columns=['NIVEL_PLAN_DEMANDA'], inplace=True)\n",
    "df_forecast_vendas_krona_PRODUTO.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Eliminar colunas NOME_CLIENTE E DESC_GRUPO_E_CLIENTE\n",
    "df_forecast_vendas_krona_PRODUTO.drop(columns=['COD_CLIENTE', 'NOME_CLIENTE', 'COD_GRUPO_CLIENTE', 'DESC_GRUPO_E_CLIENTE'], inplace=True)\n",
    "\n",
    "# Sumarizar df_forecast_vendas_krona_PRODUTO por EMPRESA, COD_PROD, DESC_PRODUTO, FAMILIA, LINHA, REGIONAL, PERIODO\n",
    "df_forecast_vendas_krona_PRODUTO = df_forecast_vendas_krona_PRODUTO.groupby(\n",
    "    ['EMPRESA', 'COD_PROD', 'DESC_PRODUTO', 'FAMILIA', 'LINHA', 'REGIONAL', 'REGIONAL_GESTOR', 'PERIODO'],\n",
    "    as_index=False\n",
    ").agg({'VOL_VENDA': 'sum'}).reset_index(drop=True)\n",
    "\n",
    "# Trazer PESO_UNIT do parquet Dim_Produtos_Vendas_krona\n",
    "# Carregar parquet Dim_Produtos_Vendas_krona\n",
    "dim_produtos_vendas_krona = pd.read_parquet(\n",
    "    pasta_input_parquet / \"Dim_Produtos_Vendas_krona.parquet\"\n",
    ")\n",
    "\n",
    "# Normalizar maiuscula coluna Nom_Empresa\n",
    "def normalizar(texto):\n",
    "    if pd.isna(texto):\n",
    "        return ''\n",
    "    return ''.join(e for e in texto.upper() if e.isalnum())\n",
    "\n",
    "dim_produtos_vendas_krona[\"Nom_Empresa\"] = dim_produtos_vendas_krona[\"Nom_Empresa\"].str.upper()\n",
    "\n",
    "# Selecionar colunas necessÃ¡rias e remover duplicatas\n",
    "dim_produtos_vendas_krona = dim_produtos_vendas_krona[['Cod_Produto', 'Nom_Empresa', 'Num_Peso']].drop_duplicates(subset=['Cod_Produto', 'Nom_Empresa'])\n",
    "\n",
    "# Merge para trazer PESO_UNIT\n",
    "df_forecast_vendas_krona_PRODUTO = pd.merge(\n",
    "    df_forecast_vendas_krona_PRODUTO,\n",
    "    dim_produtos_vendas_krona,\n",
    "    how='left',\n",
    "    left_on=['COD_PROD', 'EMPRESA'],\n",
    "    right_on=['Cod_Produto', 'Nom_Empresa']\n",
    ")\n",
    "\n",
    "# Renomear coluna Num_Peso para PESO_UNIT\n",
    "df_forecast_vendas_krona_PRODUTO.rename(columns={'Num_Peso': 'PESO_UNIT'}, inplace=True)\n",
    "\n",
    "# Eliminar colunas desnecessÃ¡rias\n",
    "df_forecast_vendas_krona_PRODUTO.drop(columns=['Cod_Produto', 'Nom_Empresa'], inplace=True)\n",
    "\n",
    "# Gerar arquivos em PARQUET\n",
    "df_forecast_vendas_krona_PRODUTO.to_parquet(pasta_staging_parquet / 'df_forecast_vendas_krona_PRODUTO.parquet', index=False)\n",
    "df_forecast_vendas_krona_CLIENTE.to_parquet(pasta_staging_parquet / 'df_forecast_vendas_krona_CLIENTE.parquet', index=False)\n",
    "\n",
    "# ðŸ“¤ ExportaÃ§Ã£o de Dados Forecast para Planejamento Colaborativo\n",
    "# ðŸ“Š NÃ­vel de agregaÃ§Ã£o: REGIONAL_GESTOR, FAMILIA e PERIODO\n",
    "\n",
    "df_Forecast_PRODUTO = df_forecast_vendas_krona_PRODUTO.groupby(\n",
    "    ['REGIONAL_GESTOR', 'REGIONAL', 'FAMILIA', 'PERIODO'],\n",
    "    as_index=False\n",
    ").agg({'VOL_VENDA': 'sum'}).reset_index(drop=True)\n",
    "df_Forecast_PRODUTO.to_csv(\n",
    "    pasta_staging_parquet / 'FORECAST_KRONA_AGREGADO.csv',\n",
    "    sep=';',\n",
    "    encoding='utf-8-sig',\n",
    "    index=False,\n",
    "    decimal=',',\n",
    "    float_format=\"%.2f\"\n",
    ")\n",
    "\n",
    "# ðŸ“¤ ExportaÃ§Ã£o de Dados Forecast para Planejamento Colaborativo\n",
    "# ðŸ“Š NÃ­vel de agregaÃ§Ã£o: REGIONAL_GESTOR, COD_GRUPO_CLIENTE, DESC_GRUPO_E_CLIENTE, FAMILIA e PERIODO\n",
    "\n",
    "df_Forecast_CLIENTE = df_forecast_vendas_krona_CLIENTE.groupby(\n",
    "    ['REGIONAL_GESTOR', 'REGIONAL', 'COD_GRUPO_CLIENTE', 'DESC_GRUPO_E_CLIENTE', 'FAMILIA', 'PERIODO'],\n",
    "    as_index=False\n",
    ").agg({'VOL_VENDA': 'sum'}).reset_index(drop=True)\n",
    "df_Forecast_CLIENTE.to_csv(\n",
    "    pasta_staging_parquet / 'FORECAST_KRONA_CLIENTE.csv',\n",
    "    sep=';',\n",
    "    encoding='utf-8-sig',\n",
    "    index=False,\n",
    "    decimal=',',\n",
    "    float_format=\"%.2f\"\n",
    ")\n",
    "\n",
    "# FIXME\n",
    "del df_forecast_desagregado, dim_produtos_vendas_krona, df_forecast_vendas_krona_PRODUTO, df_forecast_vendas_krona_CLIENTE, lista_clientes_plan_demanda\n",
    "gc.collect()\n",
    "\n",
    "print(\"âœ… Processamento EstatÃ­stico e Dados Forecast gerados com sucesso!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b935d8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "â±ï¸ Tempo total de processamento: 2 min 51.6 s\n",
      "ðŸŽ¯ Processo concluÃ­do com sucesso!\n"
     ]
    }
   ],
   "source": [
    "timer.finalizar()\n",
    "print(\"ðŸŽ¯ Processo concluÃ­do com sucesso!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748e7423",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pendencias\n",
    "# 1. Ao final do projeto, apagar os FIXME de validaÃ§Ã£o de dados que estÃ£o comentados no meio do programa\n",
    "# 2. Pendencia: Retirei dados de produtos lanÃ§amentos da lista de exclusÃ£o, pois preciso fazer previsÃ£o estatÃ­stica e considerar essa condiÃ§Ã£o conforme solicitaÃ§Ãµes da Anna no WORD\n",
    "# 3. Ver modelo de DesagregaÃ§Ã£o conforme implementao na VIQUA\n",
    "\n",
    "# Ferramenta Excel\n",
    "# 1. Direcionar consumo das bases considerando a nova pasta BD_PLAN_COLAB_FERR_EXCEL dentro da pasta_staging_parquet\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
