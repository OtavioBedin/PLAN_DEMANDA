{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa7d6663",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Mapeamento de pastas conclu√≠do com sucesso!\n"
     ]
    }
   ],
   "source": [
    "# Importando bibliotecas\n",
    "from functions import *\n",
    "import pandas as pd\n",
    "import locale\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "import logging\n",
    "from openpyxl import load_workbook\n",
    "\n",
    "timer = Temporizador()\n",
    "timer.iniciar()\n",
    "\n",
    "locale.setlocale(locale.LC_TIME, 'Portuguese_Brazil.1252')  # Para Windows\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.float_format', '{:.2f}'.format)\n",
    "pd.set_option('display.expand_frame_repr', False)\n",
    "\n",
    "# Detecta se o script est√° sendo executado de um .py ou de um notebook\n",
    "try:\n",
    "    caminho_base = Path(__file__).resolve().parent\n",
    "except NameError:\n",
    "    # __file__ n√£o existe em Jupyter ou ambiente interativo\n",
    "    caminho_base = Path.cwd()\n",
    "\n",
    "pasta_hist_vend_prev_est = caminho_base.parent / '03_HIST_VEND_PREV_EST' # Armazena arquivos hist√≥rico de vendas processados e separados por Cliente e Produto, e processados para previs√£o estat√≠stica. Armazena Parquet com Previs√£o Estat√≠stica para n√£o consumir mem√≥ria\n",
    "pasta_input_parquet = caminho_base.parent / '01_INPUT/01_BD_PARQUET'\n",
    "pasta_hist_vend_prev_est = caminho_base.parent / '03_HIST_VEND_PREV_EST'\n",
    "pasta_painel = caminho_base.parent / '04_PAINEL'\n",
    "pasta_historico_planos = caminho_base.parent / '05_HISTORICO_PLANOS'\n",
    "\n",
    "print(\"‚úÖ Mapeamento de pastas conclu√≠do com sucesso!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a12e4ac9",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Arquivos importados e preparados com sucesso!\n"
     ]
    }
   ],
   "source": [
    "# üì• Importando e preparando arquivos para desagrega√ß√£o\n",
    "\n",
    "# Ler arquivos em parquet\n",
    "df_forecast_vendas_krona_PRODUTO = pd.read_parquet(pasta_hist_vend_prev_est / 'df_forecast_vendas_krona_PRODUTO.parquet')\n",
    "df_forecast_vendas_krona_CLIENTE = pd.read_parquet(pasta_hist_vend_prev_est / 'df_forecast_vendas_krona_CLIENTE.parquet')\n",
    "\n",
    "# Ler arquivos CSV de planos de demanda\n",
    "df_plano_consenso_regional = pd.read_csv(\n",
    "    pasta_historico_planos / 'PLANO_REGIONAL.csv',\n",
    "    sep=';',              # separador de colunas\n",
    "    decimal=',',          # v√≠rgula como separador decimal\n",
    "    thousands='.',        # ponto como separador de milhar\n",
    "    engine='python'\n",
    ")\n",
    "\n",
    "df_plano_consenso_regional_gestor = pd.read_csv(\n",
    "    pasta_historico_planos / 'PLANO_REGIONAL_GESTOR.csv',\n",
    "    sep=';',              # separador de colunas\n",
    "    decimal=',',          # v√≠rgula como separador decimal\n",
    "    thousands='.',        # ponto como separador de milhar\n",
    "    engine='python'\n",
    ")\n",
    "\n",
    "df_plano_consenso_cliente = pd.read_csv(\n",
    "    pasta_historico_planos / 'PLANO_CLIENTE.csv',\n",
    "    sep=';',               # separador de colunas\n",
    "    decimal=',',           # v√≠rgula como separador decimal\n",
    "    thousands='.',         # ponto como separador de milhar\n",
    "    engine='python',\n",
    "    dtype={'COD_GRP_CLIENTE': str}   # for√ßa essa coluna como string\n",
    ")\n",
    "\n",
    "# Padronizar PERIODO como datetime\n",
    "df_plano_consenso_regional['PERIODO'] = pd.to_datetime(df_plano_consenso_regional['PERIODO'])\n",
    "df_plano_consenso_regional_gestor['PERIODO'] = pd.to_datetime(df_plano_consenso_regional_gestor['PERIODO'])\n",
    "df_plano_consenso_cliente['PERIODO'] = pd.to_datetime(df_plano_consenso_cliente['PERIODO'])\n",
    "\n",
    "# Unificar dataframes de df_plano_consenso_regional e df_plano_consenso_regional_gestor\n",
    "df_plano_consenso_regional_unificado = pd.concat([df_plano_consenso_regional, df_plano_consenso_regional_gestor], ignore_index=True)\n",
    "\n",
    "# Agrupar dados df_plano_consenso_regional_unificado somando os valores de DEMANDA_PLANEJADA\n",
    "colunas_agrupamento = ['REGIONAL_GESTOR', 'REGIONAL', 'FAMILIA', 'PERIODO']\n",
    "df_plano_consenso_regional_unificado_grouped = df_plano_consenso_regional_unificado.groupby(colunas_agrupamento)['VALOR'].sum().reset_index()\n",
    "\n",
    "# Agrupar dados df_plano_consenso_cliente somando os valores de DEMANDA_PLANEJADA\n",
    "colunas_agrupamento = ['COD_GRP_CLIENTE', 'REGIONAL_GESTOR', 'REGIONAL', 'FAMILIA', 'PERIODO']\n",
    "df_plano_consenso_cliente_grouped = df_plano_consenso_cliente.groupby(colunas_agrupamento)['VALOR'].sum().reset_index()\n",
    "\n",
    "# Guardar variavel versao do plano da coluna VERSAO_PLANO, retornando um valor da coluna VERSAO_PLANO do df_plano_consenso_regional\n",
    "versao_plano = df_plano_consenso_regional['VERSAO_PLANO'].iloc[0]\n",
    "\n",
    "print(\"‚úÖ Arquivos importados e preparados com sucesso!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28ff03d3",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "# üì• Desagrega√ß√£o dos plano REGIONAL\n",
    "\n",
    "# Calculando a participa√ß√£o da cada linha de produto no volume total da combina√ß√£o de chaves - REGIONAL_GESTOR, REGIONAL, FAMILIA, PERIODO\n",
    "df_volume_desag_regional = df_forecast_vendas_krona_PRODUTO.copy()\n",
    "\n",
    "chaves = ['REGIONAL_GESTOR', 'REGIONAL', 'FAMILIA', 'PERIODO']\n",
    "\n",
    "# total por combina√ß√£o\n",
    "df_volume_desag_regional['TOTAL'] = df_volume_desag_regional.groupby(chaves)['VOL_VENDA'].transform('sum')\n",
    "\n",
    "# participa√ß√£o da linha dentro da combina√ß√£o\n",
    "df_volume_desag_regional['PARTIC'] = np.where(\n",
    "    df_volume_desag_regional['TOTAL'] > 0,\n",
    "    df_volume_desag_regional['VOL_VENDA'] / df_volume_desag_regional['TOTAL'],\n",
    "    0\n",
    ")\n",
    "\n",
    "# Mesclar participa√ß√£o com o plano consenso regional unificado\n",
    "df_volume_desag_regional = pd.merge(\n",
    "    df_volume_desag_regional,\n",
    "    df_plano_consenso_regional_unificado_grouped,\n",
    "    on=chaves,\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Renomear colunas VALOR E VOL_VENDA para evitar conflitos\n",
    "df_volume_desag_regional.rename(columns={'VOL_VENDA': 'VOL_ESTATISTICO'}, inplace=True)\n",
    "df_volume_desag_regional.rename(columns={'VALOR': 'VOL_CONSENSO'}, inplace=True)\n",
    "\n",
    "# Calcular desagrega√ß√£o\n",
    "df_volume_desag_regional['VOL_CONSENSO'] = df_volume_desag_regional['PARTIC'] * df_volume_desag_regional['VOL_CONSENSO']\n",
    "\n",
    "# Excluir colunas PESO_UNIT, TOTAL e PARTIC\n",
    "df_volume_desag_regional.drop(columns=['PESO_UNIT', 'TOTAL', 'PARTIC'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a41af4f",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Desagrega√ß√£o conclu√≠da com sucesso!\n"
     ]
    }
   ],
   "source": [
    "# üì• Desagrega√ß√£o dos plano CLIENTE\n",
    "\n",
    "# Calculando a participa√ß√£o da cada linha de produto no volume total da combina√ß√£o de chaves - REGIONAL_GESTOR, REGIONAL, FAMILIA, PERIODO\n",
    "df_volume_desag_cliente = df_forecast_vendas_krona_CLIENTE.copy()\n",
    "\n",
    "# Renomear coluna COD_GRP_CLIENTE para COD_GRUPO_CLIENTE para manter padr√£o\n",
    "df_volume_desag_cliente.rename(columns={'COD_GRUPO_CLIENTE': 'COD_GRP_CLIENTE'}, inplace=True)\n",
    "\n",
    "chaves = ['COD_GRP_CLIENTE', 'REGIONAL_GESTOR', 'REGIONAL', 'FAMILIA', 'PERIODO']\n",
    "\n",
    "# total por combina√ß√£o\n",
    "df_volume_desag_cliente['TOTAL'] = df_volume_desag_cliente.groupby(chaves)['VOL_VENDA'].transform('sum')\n",
    "\n",
    "# participa√ß√£o da linha dentro da combina√ß√£o\n",
    "df_volume_desag_cliente['PARTIC'] = np.where(\n",
    "    df_volume_desag_cliente['TOTAL'] > 0,\n",
    "    df_volume_desag_cliente['VOL_VENDA'] / df_volume_desag_cliente['TOTAL'],\n",
    "    0\n",
    ")\n",
    "\n",
    "# Mesclar participa√ß√£o com o plano consenso regional unificado\n",
    "df_volume_desag_cliente = pd.merge(\n",
    "    df_volume_desag_cliente,\n",
    "    df_plano_consenso_cliente_grouped,\n",
    "    on=chaves,\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Renomear colunas VALOR E VOL_VENDA para evitar conflitos\n",
    "df_volume_desag_cliente.rename(columns={'VOL_VENDA': 'VOL_ESTATISTICO'}, inplace=True)\n",
    "df_volume_desag_cliente.rename(columns={'VALOR': 'VOL_CONSENSO'}, inplace=True)\n",
    "\n",
    "# Calcular desagrega√ß√£o\n",
    "df_volume_desag_cliente['VOL_CONSENSO'] = df_volume_desag_cliente['PARTIC'] * df_volume_desag_cliente['VOL_CONSENSO']\n",
    "\n",
    "# Excluir colunas TOTAL e PARTIC\n",
    "df_volume_desag_cliente.drop(columns=['TOTAL', 'PARTIC'], inplace=True)\n",
    "\n",
    "print(\"‚úÖ Desagrega√ß√£o conclu√≠da com sucesso!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98511454",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Volumes gerados, bases geradas, plano para produ√ß√£o gerado com sucesso!\n"
     ]
    }
   ],
   "source": [
    "# üì• Unifica√ß√£o de dados CLIENTE E REGIONAL\n",
    "\n",
    "# Agrupar dados df_volume_desag_cliente\n",
    "colunas_agrupar = ['EMPRESA', 'COD_PROD', 'DESC_PRODUTO', 'FAMILIA', 'LINHA', 'REGIONAL', 'REGIONAL_GESTOR', 'PERIODO']\n",
    "\n",
    "df_volume_desag_cliente_agrupado = df_volume_desag_cliente.groupby(colunas_agrupar).agg({\n",
    "    'VOL_ESTATISTICO': 'sum',\n",
    "    'VOL_CONSENSO': 'sum'\n",
    "}).reset_index()\n",
    "\n",
    "# Unificar dataframes de df_volume_desag_regional e df_volume_desag_cliente_agrupado\n",
    "df_plano_final_krona = pd.concat([df_volume_desag_regional, df_volume_desag_cliente_agrupado], ignore_index=True)\n",
    "\n",
    "# Agrupar dados df_plano_final_krona somando os valores de VOL_ESTATISTICO e VOL_CONSENSO\n",
    "colunas_agrupamento_final = ['EMPRESA', 'COD_PROD', 'DESC_PRODUTO', 'FAMILIA', 'LINHA', 'REGIONAL', 'REGIONAL_GESTOR', 'PERIODO']\n",
    "df_plano_final_krona = df_plano_final_krona.groupby(colunas_agrupamento_final).agg({\n",
    "    'VOL_ESTATISTICO': 'sum',\n",
    "    'VOL_CONSENSO': 'sum'\n",
    "}).reset_index()\n",
    "\n",
    "# Carregar parquet Dim_Produtos_Vendas_krona para buscar peso unit√°rio\n",
    "df_dim_produtos_vendas_krona = pd.read_parquet(pasta_input_parquet / 'Dim_Produtos_Vendas_krona.parquet')\n",
    "df_dim_produtos_vendas_krona['Cod_Produto'] = df_dim_produtos_vendas_krona['Cod_Produto'].astype(str)\n",
    "df_dim_produtos_vendas_krona['Nom_Empresa'] = df_dim_produtos_vendas_krona['Nom_Empresa'].str.upper()\n",
    "\n",
    "# Manter somente colunas necess√°rias\n",
    "colunas_dim_produtos = ['Cod_Produto', 'Nom_Empresa', 'Num_Peso']\n",
    "df_dim_produtos_vendas_krona = df_dim_produtos_vendas_krona[colunas_dim_produtos]\n",
    "\n",
    "# Renomear colunas para facilitar merge\n",
    "df_dim_produtos_vendas_krona.rename(columns={'Cod_Produto': 'COD_PROD', 'Nom_Empresa': 'EMPRESA', 'Num_Peso': 'PESO_UNIT'}, inplace=True)\n",
    "\n",
    "# Mesclar peso unit√°rio com o plano final\n",
    "df_plano_final_krona = pd.merge(\n",
    "    df_plano_final_krona,\n",
    "    df_dim_produtos_vendas_krona,\n",
    "    on=['EMPRESA', 'COD_PROD'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "df_plano_final_krona['QTD_CONSENSO'] = df_plano_final_krona['VOL_CONSENSO'] / df_plano_final_krona['PESO_UNIT']\n",
    "df_plano_final_krona['QTD_ESTATISTICO'] = df_plano_final_krona['VOL_ESTATISTICO'] / df_plano_final_krona['PESO_UNIT']\n",
    "\n",
    "# Adicionar coluna de vers√£o do plano\n",
    "df_plano_final_krona['VERSAO_PLANO'] = versao_plano\n",
    "\n",
    "# Carregar parquet com Demanda de Lan√ßamento\n",
    "df_produtos_lancamento = pd.read_parquet(pasta_hist_vend_prev_est / 'DEMANDA_LANCAMENTO_PRODUTOS_KRONA.parquet')\n",
    "\n",
    "# Renomear colunas para facilitar merge\n",
    "df_produtos_lancamento.rename(columns={'CD': 'EMPRESA'}, inplace=True)\n",
    "\n",
    "# Filtrar colunda EMPRESA de df_produtos_lancamento que contenha KRONA\n",
    "df_produtos_lancamento = df_produtos_lancamento[df_produtos_lancamento['EMPRESA'].str.contains('KRONA')]\n",
    "\n",
    "# Filtrar PERIODO da df_produtos_lancamento pelas datas que constam na df_plano_final_krona\n",
    "periodos_plano = df_plano_final_krona['PERIODO'].unique()\n",
    "df_produtos_lancamento = df_produtos_lancamento[df_produtos_lancamento['PERIODO'].isin(periodos_plano)].reset_index(drop=True)\n",
    "\n",
    "# Expandir produtos de lan√ßamento para cobrir todos os per√≠odos do plano\n",
    "def expandir_produtos_lancamento(df_produtos_lancamento, periodos_plano):\n",
    "    \"\"\"\n",
    "    Expande o dataframe de lan√ßamentos para cobrir todos os per√≠odos do plano.\n",
    "    Se faltar per√≠odo, duplica a demanda do √∫ltimo m√™s dispon√≠vel.\n",
    "    Adiciona coluna STATUS para diferenciar demanda existente e criada.\n",
    "    \"\"\"\n",
    "    def expandir_grupo(grupo):\n",
    "        grupo = grupo.sort_values('PERIODO')\n",
    "        ultimo_valor = grupo['QTD'].iloc[-1]\n",
    "        existentes = grupo['PERIODO'].unique()\n",
    "        faltantes = [p for p in periodos_plano if p not in existentes]\n",
    "\n",
    "        grupo['STATUS'] = 'DEMANDA_EXISTENTE'\n",
    "\n",
    "        if faltantes:\n",
    "            novos = pd.DataFrame({\n",
    "                'COD_PROD': grupo['COD_PROD'].iloc[0],\n",
    "                'EMPRESA': grupo['EMPRESA'].iloc[0],\n",
    "                'PERIODO': faltantes,\n",
    "                'QTD': ultimo_valor,\n",
    "                'STATUS': 'DEMANDA_CRIADA'\n",
    "            })\n",
    "            grupo = pd.concat([grupo, novos], ignore_index=True)\n",
    "\n",
    "        return grupo\n",
    "\n",
    "    # üöÄ iterando manualmente pelos grupos (sem apply ‚Üí sem warning)\n",
    "    grupos_expandidos = []\n",
    "    for _, grupo in df_produtos_lancamento.groupby(['COD_PROD','EMPRESA']):\n",
    "        grupos_expandidos.append(expandir_grupo(grupo))\n",
    "\n",
    "    df_expandido = pd.concat(grupos_expandidos, ignore_index=True)\n",
    "    df_expandido = df_expandido.sort_values(['COD_PROD','EMPRESA','PERIODO'])\n",
    "\n",
    "    return df_expandido\n",
    "\n",
    "df_lancamentos_expandido = expandir_produtos_lancamento(df_produtos_lancamento, periodos_plano)\n",
    "\n",
    "# Salvar df_lancamentos_expandido em excel\n",
    "df_lancamentos_expandido.to_excel(pasta_historico_planos / f'PLANO_LANCAMENTOS_EXPANDIDO.xlsx', index=False)\n",
    "\n",
    "# Criar colunas no df_lancamentos_expandido que faltam para unir com o df_plano_final_krona\n",
    "df_lancamentos_expandido['DESC_PRODUTO'] = ''\n",
    "df_lancamentos_expandido['FAMILIA'] = ''\n",
    "df_lancamentos_expandido['LINHA'] = ''\n",
    "df_lancamentos_expandido['REGIONAL'] = ''\n",
    "df_lancamentos_expandido['REGIONAL_GESTOR'] = ''\n",
    "df_lancamentos_expandido['VOL_ESTATISTICO'] = 0\n",
    "df_lancamentos_expandido['VOL_CONSENSO'] = 0\n",
    "df_lancamentos_expandido['PESO_UNIT'] = 0\n",
    "df_lancamentos_expandido['QTD_ESTATISTICO'] = 0\n",
    "df_lancamentos_expandido['VERSAO_PLANO'] = versao_plano\n",
    "\n",
    "# Renomear coluna QTD para QTD_CONSENSO\n",
    "df_lancamentos_expandido.rename(columns={'QTD': 'QTD_CONSENSO'}, inplace=True)\n",
    "\n",
    "# Ordenar colunas do df_lancamentos_expandido para ficar igual ao df_plano_final_krona\n",
    "colunas_ordem = df_plano_final_krona.columns.tolist()\n",
    "df_lancamentos_expandido = df_lancamentos_expandido[colunas_ordem]\n",
    "\n",
    "# Unir df_plano_final_krona com df_lancamentos_expandido\n",
    "df_plano_final_krona = pd.concat([df_plano_final_krona, df_lancamentos_expandido], ignore_index=True)\n",
    "\n",
    "# Salvar em um banco de dados em Parquet, adicionando a vers√£o do plano na nomenclatura do arquivo\n",
    "df_plano_final_krona.to_parquet(pasta_historico_planos / \"BD_PLANOS\" / f'PLANO_CONSENSO_KRONA_{versao_plano}.parquet', index=False)\n",
    "\n",
    "# Agrupar dados e gerar plano para calculo de produ√ß√£o\n",
    "df_demanda_plano_producao = df_plano_final_krona.groupby(['COD_PROD', 'EMPRESA', 'PERIODO']).agg({\n",
    "    'QTD_CONSENSO': 'sum'\n",
    "}).reset_index()\n",
    "\n",
    "# Salvar plano de demanda em Excel, gerando um arquivo por EMPRESA, excluir coluna EMPRESA e renomear as colunas antes de enviar\n",
    "for empresa, grupo in df_demanda_plano_producao.groupby('EMPRESA'):\n",
    "    grupo['Alm.'] = 1\n",
    "    grupo = grupo.drop(columns=['EMPRESA']).rename(columns={\n",
    "        'COD_PROD': 'Cod',\n",
    "        'PERIODO': 'Dt.',\n",
    "        'QTD_CONSENSO': 'Qtde.'\n",
    "    })\n",
    "    grupo = grupo[['Cod', 'Alm.', 'Qtde.', 'Dt.']]\n",
    "    grupo['Dt.'] = grupo['Dt.'].dt.date\n",
    "\n",
    "    grupo.to_csv(\n",
    "        pasta_historico_planos / 'PLANOS_PCP' / f'DEMANDA_LTP_{empresa}_{versao_plano}.csv',\n",
    "        index=False,\n",
    "        sep=';',\n",
    "        decimal=','\n",
    "    )\n",
    "\n",
    "    # grupo.to_excel(pasta_historico_planos / 'PLANOS_PCP' / f'DEMANDA_LTP_{empresa}_{versao_plano}.xlsx', index=False)\n",
    "\n",
    "print(\"‚úÖ Volumes gerados, bases geradas, plano para produ√ß√£o gerado com sucesso!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b935d8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚è±Ô∏è Tempo total de processamento: 0 min 0.7 s\n",
      "üéØ Processo conclu√≠do com sucesso!\n"
     ]
    }
   ],
   "source": [
    "timer.finalizar()\n",
    "print(\"üéØ Processo conclu√≠do com sucesso!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
