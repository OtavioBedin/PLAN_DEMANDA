{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39deb110",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Mapeamento de pastas conclu√≠do com sucesso!\n"
     ]
    }
   ],
   "source": [
    "# Importando bibliotecas\n",
    "from functions import *\n",
    "import pandas as pd\n",
    "import locale\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import duckdb\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from prophet import Prophet\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import warnings\n",
    "import logging\n",
    "import polars as pl\n",
    "import shutil\n",
    "\n",
    "\n",
    "logging.basicConfig(level=logging.WARNING, format='%(message)s')\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "timer = Temporizador()\n",
    "timer.iniciar()\n",
    "\n",
    "locale.setlocale(locale.LC_TIME, 'Portuguese_Brazil.1252')  # Para Windows\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.float_format', '{:.2f}'.format)\n",
    "pd.set_option('display.expand_frame_repr', False)\n",
    "\n",
    "# Detecta se o script est√° sendo executado de um .py ou de um notebook\n",
    "try:\n",
    "    caminho_base = Path(__file__).resolve().parent\n",
    "except NameError:\n",
    "    # __file__ n√£o existe em Jupyter ou ambiente interativo\n",
    "    caminho_base = Path.cwd()\n",
    "\n",
    "pasta_input_parquet = caminho_base.parent / '01_INPUT_PIPELINE/01_BD_PARQUET'\n",
    "arquivo_input_regras_negocio = caminho_base.parent / '01_INPUT_PIPELINE/02_REGRAS_NEGOCIO/VIQUA_REGRAS.xlsm'\n",
    "pasta_staging_parquet = caminho_base.parent / '02_STAGING_PARQUET' # Armazena arquivos parquet com tratamentos, aplica√ß√µes de regras, depara, etc\n",
    "pasta_input_painel = caminho_base.parent / '03_INPUT_PAINEL' # Armazena arquivos que ser√£o consumidos no painel de S&OP para os gerentes\n",
    "pasta_painel = caminho_base.parent / '05_PAINEL'\n",
    "\n",
    "# Eliminar arquivos das pastas de 02_STAGING_PARQUET e 03_INPUT_PAINEL que ser√£o regenerados\n",
    "pastas_para_limpar = [\n",
    "    pasta_staging_parquet,\n",
    "    pasta_input_painel,\n",
    "]\n",
    "\n",
    "for pasta in pastas_para_limpar:\n",
    "    if pasta.exists() and pasta.is_dir():\n",
    "        for item in pasta.iterdir():\n",
    "            if item.is_file() or item.is_symlink():\n",
    "                item.unlink()\n",
    "            elif item.is_dir():\n",
    "                shutil.rmtree(item)\n",
    "\n",
    "print(\"‚úÖ Mapeamento de pastas conclu√≠do com sucesso!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "150711dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Importa√ß√£o e tratamento de dados Historicos e conclu√≠dos com sucesso!\n"
     ]
    }
   ],
   "source": [
    "caminho_fato_vend = (pasta_input_parquet / \"Fato_Vendas_Viqua.parquet\").as_posix()\n",
    "caminho_dim_prod = (pasta_input_parquet / \"Dim_Produtos_Viqua.parquet\").as_posix()\n",
    "caminho_dim_cli  = (pasta_input_parquet / \"Dim_Clientes_Viqua.parquet\").as_posix()\n",
    "caminho_dim_repr = (pasta_input_parquet / \"Dim_Representante_Viqua.parquet\").as_posix()\n",
    "\n",
    "df_vendas_viqua = duckdb.query(f\"\"\"\n",
    "    WITH\n",
    "    fato AS (\n",
    "        SELECT\n",
    "            Chv_Produto,\n",
    "            Chv_Cliente,\n",
    "            STRFTIME(DATE_TRUNC('month', Dat_Entrega), '%Y%m') AS PERIODO,\n",
    "            TRY_CAST(Qtd_Venda AS DOUBLE) AS QTD\n",
    "        FROM read_parquet('{caminho_fato_vend}')\n",
    "        WHERE Dat_Entrega IS NOT NULL\n",
    "          AND Dat_Entrega >= DATE '2022-01-01'\n",
    "          \n",
    "    ),\n",
    "    prod AS (\n",
    "        SELECT\n",
    "            Chv_Produto,\n",
    "            TRIM(Cod_Produto) AS COD_PROD,\n",
    "            UPPER(TRIM(Des_Produto)) AS DESC_PROD,\n",
    "            UPPER(TRIM(Des_Grupo)) AS GRUPO_PROD,\n",
    "            Cod_Familia,\n",
    "            UPPER(TRIM(Des_Familia)) AS DESC_FAMILIA\n",
    "        FROM read_parquet('{caminho_dim_prod}')\n",
    "    ),\n",
    "    cli AS (\n",
    "        SELECT\n",
    "            Chv_Cliente,\n",
    "            TRIM(Cod_Cliente) AS COD_CLIENTE,\n",
    "            UPPER(TRIM(Nom_Cliente)) AS NOM_CLIENTE,\n",
    "            Chv_Representante_Cliente\n",
    "        FROM read_parquet('{caminho_dim_cli}')\n",
    "    ),\n",
    "    repr AS (\n",
    "        SELECT\n",
    "            Chv_Representante,\n",
    "            UPPER(TRIM(Nom_Regional)) AS REGIONAL\n",
    "        FROM read_parquet('{caminho_dim_repr}')\n",
    "    )\n",
    "    SELECT\n",
    "        p.COD_PROD,\n",
    "        p.DESC_PROD,\n",
    "        CAST(p.Cod_Familia AS VARCHAR) || ' - ' || p.DESC_FAMILIA AS FAMILIA,\n",
    "        p.GRUPO_PROD,\n",
    "        c.COD_CLIENTE,\n",
    "        c.NOM_CLIENTE,\n",
    "        r.REGIONAL,\n",
    "        SUM(f.QTD) AS QTD,\n",
    "        f.PERIODO\n",
    "    FROM fato f\n",
    "    LEFT JOIN prod p ON f.Chv_Produto = p.Chv_Produto\n",
    "    LEFT JOIN cli c ON f.Chv_Cliente = c.Chv_Cliente\n",
    "    LEFT JOIN repr r ON c.Chv_Representante_Cliente = r.Chv_Representante\n",
    "    GROUP BY\n",
    "        p.COD_PROD,\n",
    "        p.DESC_PROD,\n",
    "        p.Cod_Familia,\n",
    "        p.DESC_FAMILIA,\n",
    "        p.GRUPO_PROD,\n",
    "        c.COD_CLIENTE,\n",
    "        c.NOM_CLIENTE,\n",
    "        r.REGIONAL,\n",
    "        f.PERIODO\n",
    "\"\"\").df()\n",
    "\n",
    "# Eliminar zeros de vendas e vazios ou nulos\n",
    "df_vendas_viqua = df_vendas_viqua[(df_vendas_viqua[\"QTD\"] > 0) & (df_vendas_viqua[\"COD_CLIENTE\"].notna()) & (df_vendas_viqua[\"COD_CLIENTE\"] != 'null')]\n",
    "\n",
    "# salva em parquet\n",
    "df_vendas_viqua.to_parquet(pasta_staging_parquet / \"df_vendas_viqua.parquet\", index=False)\n",
    "\n",
    "print(\"‚úÖ Importa√ß√£o e tratamento de dados Historicos e conclu√≠dos com sucesso!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0e935ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COD_PROD</th>\n",
       "      <th>FAMILIA</th>\n",
       "      <th>GRUPO_PROD</th>\n",
       "      <th>PERIODO</th>\n",
       "      <th>QTD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101725</td>\n",
       "      <td>85 - MOLDES</td>\n",
       "      <td>MAQUINAS E EQUIPAMENTOS</td>\n",
       "      <td>202201</td>\n",
       "      <td>10.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>101725</td>\n",
       "      <td>85 - MOLDES</td>\n",
       "      <td>MAQUINAS E EQUIPAMENTOS</td>\n",
       "      <td>202208</td>\n",
       "      <td>12.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>101725</td>\n",
       "      <td>85 - MOLDES</td>\n",
       "      <td>MAQUINAS E EQUIPAMENTOS</td>\n",
       "      <td>202209</td>\n",
       "      <td>10.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>101725</td>\n",
       "      <td>85 - MOLDES</td>\n",
       "      <td>MAQUINAS E EQUIPAMENTOS</td>\n",
       "      <td>202301</td>\n",
       "      <td>4.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>101725</td>\n",
       "      <td>85 - MOLDES</td>\n",
       "      <td>MAQUINAS E EQUIPAMENTOS</td>\n",
       "      <td>202303</td>\n",
       "      <td>10.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34138</th>\n",
       "      <td>EXP11CO</td>\n",
       "      <td>33 - EXPOSITOR</td>\n",
       "      <td>OUTROS</td>\n",
       "      <td>202508</td>\n",
       "      <td>23.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34139</th>\n",
       "      <td>EXP11CO</td>\n",
       "      <td>33 - EXPOSITOR</td>\n",
       "      <td>OUTROS</td>\n",
       "      <td>202509</td>\n",
       "      <td>32.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34140</th>\n",
       "      <td>EXP11CO</td>\n",
       "      <td>33 - EXPOSITOR</td>\n",
       "      <td>OUTROS</td>\n",
       "      <td>202510</td>\n",
       "      <td>37.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34141</th>\n",
       "      <td>EXP11CO</td>\n",
       "      <td>33 - EXPOSITOR</td>\n",
       "      <td>OUTROS</td>\n",
       "      <td>202511</td>\n",
       "      <td>24.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34142</th>\n",
       "      <td>EXP11CO</td>\n",
       "      <td>33 - EXPOSITOR</td>\n",
       "      <td>OUTROS</td>\n",
       "      <td>202512</td>\n",
       "      <td>12.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34143 rows √ó 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      COD_PROD         FAMILIA               GRUPO_PROD PERIODO   QTD\n",
       "0       101725     85 - MOLDES  MAQUINAS E EQUIPAMENTOS  202201 10.00\n",
       "1       101725     85 - MOLDES  MAQUINAS E EQUIPAMENTOS  202208 12.00\n",
       "2       101725     85 - MOLDES  MAQUINAS E EQUIPAMENTOS  202209 10.00\n",
       "3       101725     85 - MOLDES  MAQUINAS E EQUIPAMENTOS  202301  4.00\n",
       "4       101725     85 - MOLDES  MAQUINAS E EQUIPAMENTOS  202303 10.00\n",
       "...        ...             ...                      ...     ...   ...\n",
       "34138  EXP11CO  33 - EXPOSITOR                   OUTROS  202508 23.00\n",
       "34139  EXP11CO  33 - EXPOSITOR                   OUTROS  202509 32.00\n",
       "34140  EXP11CO  33 - EXPOSITOR                   OUTROS  202510 37.00\n",
       "34141  EXP11CO  33 - EXPOSITOR                   OUTROS  202511 24.00\n",
       "34142  EXP11CO  33 - EXPOSITOR                   OUTROS  202512 12.00\n",
       "\n",
       "[34143 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# FIXME APAGAR ESSA CELULA AP√ìS VALIDA√á√ÉO ANNA\n",
    "# Agrupar dados QTD, por COD_PROD, FAMILIA, GRUPO_PROD, PERIODO\n",
    "df_vendas_viqua_validacao_Anna = df_vendas_viqua.groupby(\n",
    "    ['COD_PROD', 'FAMILIA', 'GRUPO_PROD', 'PERIODO'],\n",
    "    as_index=False\n",
    ").agg({'QTD': 'sum'})\n",
    "\n",
    "\n",
    "# # Gerar Excel para Anna\n",
    "caminho_excel_saida = pasta_painel / f\"VALIDACAO_ANNA_VIQUA_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx\"\n",
    "df_vendas_viqua_validacao_Anna.to_excel(caminho_excel_saida, index=False)\n",
    "df_vendas_viqua_validacao_Anna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58068c62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Importa√ß√£o e tratamento de dados do arquivo VIQUA_REGRAS, conclu√≠dos com sucesso!\n"
     ]
    }
   ],
   "source": [
    "# Carregar dados arquivo VIQUA_REGRAS\n",
    "caminho_arquivo = arquivo_input_regras_negocio\n",
    "\n",
    "# Carrregar os produtos a eliminar\n",
    "guia_excel = 'PRODUTOS_ELIMINAR'\n",
    "df_produtos_eliminar = pd.read_excel(caminho_arquivo, sheet_name=guia_excel, engine='calamine')\n",
    "df_produtos_eliminar['COD_PROD'] = df_produtos_eliminar['COD_PROD'].astype(str)\n",
    "df_produtos_eliminar = df_produtos_eliminar.drop_duplicates(subset=['COD_PROD'])\n",
    "\n",
    "# Carrregar Regionais Gestor para DEPARA de Regionais\n",
    "guia_excel = 'REGIONAIS_GESTOR'\n",
    "df_regionais_gestor = pd.read_excel(caminho_arquivo, sheet_name=guia_excel, engine='calamine')\n",
    "df_regionais_gestor = df_regionais_gestor.drop_duplicates(subset=['REGIONAL', 'REGIONAL_GESTOR'])\n",
    "\n",
    "# Carrregar os Clientes que devem ter processo de Demanda\n",
    "guia_excel = 'CLIENTES_DEMANDA'\n",
    "df_clientes_demanda = pd.read_excel(caminho_arquivo, sheet_name=guia_excel, engine='calamine')\n",
    "df_clientes_demanda['Cod_Grupo_Cliente'] = df_clientes_demanda['Cod_Grupo_Cliente'].astype(str)\n",
    "df_clientes_demanda = df_clientes_demanda.drop_duplicates(subset=['Cod_Grupo_Cliente'])\n",
    "\n",
    "# Carregar demanda de novos produtos\n",
    "guia_excel = 'PRODUTOS_LANCAMENTOS'\n",
    "df_produtos_lancamento = pd.read_excel(caminho_arquivo, sheet_name=guia_excel, engine='calamine')\n",
    "# üö® VALIDAR SE EXISTEM DADOS\n",
    "if df_produtos_lancamento.empty:\n",
    "    raise ValueError(\n",
    "        \"‚ùå ERRO: Nenhuma informa√ß√£o foi encontrada na aba PRODUTOS_LANCAMENTOS.\\n\"\n",
    "        \"‚û°Ô∏è Verifique se a planilha possui dados v√°lidos antes de executar o pipeline.\"\n",
    "    )\n",
    "df_produtos_lancamento['JANELA LAN√áAMENTO'] = df_produtos_lancamento['JANELA LAN√áAMENTO'].astype(str).str.strip()\n",
    "df_produtos_lancamento = df_produtos_lancamento[df_produtos_lancamento['JANELA LAN√áAMENTO'] != ''].reset_index(drop=True)\n",
    "df_produtos_lancamento.rename(columns={'COD': 'COD_PROD'}, inplace=True)\n",
    "df_produtos_lancamento = df_produtos_lancamento[df_produtos_lancamento['COD_PROD'].notna()].reset_index(drop=True)\n",
    "df_produtos_lancamento['COD_PROD'] = df_produtos_lancamento['COD_PROD'].astype(str)\n",
    "\n",
    "# Identifica colunas com datas v√°lidas\n",
    "col_datas = []\n",
    "for col in df_produtos_lancamento.columns:\n",
    "    try:\n",
    "        pd.to_datetime(col, dayfirst=True, errors='raise')\n",
    "        col_datas.append(col)\n",
    "    except (ValueError, TypeError):\n",
    "        continue\n",
    "\n",
    "colunas_validas = ['COD_PROD'] + \\\n",
    "                    [col for col in df_produtos_lancamento.columns if 'CD:' in str(col)] + \\\n",
    "                    col_datas\n",
    "df_produtos_lancamento = df_produtos_lancamento[[col for col in colunas_validas if col in df_produtos_lancamento.columns]]\n",
    "\n",
    "# Transforma datas em linhas\n",
    "df_produtos_lancamento = df_produtos_lancamento.melt(\n",
    "    id_vars=[col for col in df_produtos_lancamento.columns if col not in col_datas],\n",
    "    value_vars=col_datas,\n",
    "    var_name='PERIODO',\n",
    "    value_name='VALOR'\n",
    ")\n",
    "df_produtos_lancamento = df_produtos_lancamento[df_produtos_lancamento['VALOR'].notna()].reset_index(drop=True)\n",
    "\n",
    "# Multiplica colunas CD pelo VALOR\n",
    "colunas_cd = [col for col in df_produtos_lancamento.columns if 'CD:' in str(col)]\n",
    "for col in colunas_cd:\n",
    "    df_produtos_lancamento[col] = df_produtos_lancamento[col] * df_produtos_lancamento['VALOR']\n",
    "df_produtos_lancamento.drop(columns=['VALOR'], inplace=True)\n",
    "\n",
    "# Transforma colunas CD em linhas\n",
    "df_produtos_lancamento = df_produtos_lancamento.melt(\n",
    "    id_vars=[col for col in df_produtos_lancamento.columns if col not in colunas_cd],\n",
    "    value_vars=colunas_cd,\n",
    "    var_name='CD',\n",
    "    value_name='QTD'\n",
    ")\n",
    "\n",
    "# Carrega aba de DE-PARA\n",
    "guia_excel = 'DE_PARA_CD'\n",
    "df_depara = pd.read_excel(caminho_arquivo, sheet_name=guia_excel, engine='calamine')\n",
    "df_produtos_lancamento = df_produtos_lancamento.merge(df_depara[['DE', 'PARA']], how='left', left_on='CD', right_on='DE')\n",
    "df_produtos_lancamento.drop(columns=['DE', 'CD'], inplace=True)\n",
    "df_produtos_lancamento.insert(2, 'PARA', df_produtos_lancamento.pop('PARA'))\n",
    "df_produtos_lancamento.rename(columns={'PARA': 'CD'}, inplace=True)\n",
    "\n",
    "# Agrupa e limpa\n",
    "df_produtos_lancamento = df_produtos_lancamento.groupby(['COD_PROD', 'CD', 'PERIODO'], as_index=False)['QTD'].sum()\n",
    "df_produtos_lancamento = df_produtos_lancamento[df_produtos_lancamento['QTD'].notna() & (df_produtos_lancamento['QTD'] != 0)].reset_index(drop=True)\n",
    "df_produtos_lancamento['CD'] = df_produtos_lancamento['CD'].str.normalize('NFKD').str.encode('ascii', errors='ignore').str.decode('utf-8').str.upper()\n",
    "\n",
    "# Criar lista de produtos para eliminar, somente com  df_produtos_eliminar\n",
    "# df_produtos_lancamento vamos prever devido ao problema apontado pela Anna, onde a previs√£o de lan√ßamentos pode n√£o cobrir lacunas dos per√≠odos de S&OP\n",
    "lista_produtos_eliminar = list(set(df_produtos_eliminar['COD_PROD'].tolist()))\n",
    "                               \n",
    "# Eliminar linhas do df_vendas_viqua que tenham COD_PROD presente na lista\n",
    "df_vendas_viqua = df_vendas_viqua[~df_vendas_viqua['COD_PROD'].isin(lista_produtos_eliminar)].reset_index(drop=True)\n",
    "\n",
    "print(\"‚úÖ Importa√ß√£o e tratamento de dados do arquivo VIQUA_REGRAS, conclu√≠dos com sucesso!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b65b992",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Iniciando processo de previs√£o estat√≠stica...\n",
      "üîÑ Usando PERIODO j√° no formato AAAAMM...\n",
      "üîÑ Criando calend√°rio futuro (Fev/26 ‚Üí Jul/26)...\n",
      "üîÑ Gerando previs√£o por SKU...\n"
     ]
    }
   ],
   "source": [
    "print(\"üîÑ Iniciando processo de previs√£o estat√≠stica...\")\n",
    "\n",
    "# ============================================================\n",
    "# LIMPEZA SUAVE DE OUTLIERS\n",
    "# ============================================================\n",
    "\n",
    "def smooth_outliers(series, z=2.5):\n",
    "    if series.std() == 0:\n",
    "        return series\n",
    "    mean = series.mean()\n",
    "    std = series.std()\n",
    "    upper = mean + z * std\n",
    "    lower = max(0, mean - z * std)\n",
    "    return series.clip(lower, upper)\n",
    "\n",
    "# ============================================================\n",
    "# CROSTON ‚Äì demanda intermitente\n",
    "# ============================================================\n",
    "\n",
    "def croston(ts, h=6):\n",
    "    ts = np.array(ts)\n",
    "    if len(ts) == 0 or ts.sum() == 0:\n",
    "        return np.zeros(h)\n",
    "\n",
    "    demand = ts[ts > 0]\n",
    "    intervals = np.diff(np.where(ts > 0)[0])\n",
    "    mean_interval = intervals.mean() if len(intervals) > 0 else 1\n",
    "\n",
    "    q = demand.mean()\n",
    "    p = mean_interval\n",
    "\n",
    "    fc = (q / p) * np.ones(h)\n",
    "    return np.maximum(fc, 0)  # <<< TRAVA NEGATIVO\n",
    "\n",
    "# ============================================================\n",
    "# MODELO H√çBRIDO\n",
    "# ============================================================\n",
    "\n",
    "def forecast_sku(df_sku, horizon=6):\n",
    "    df_sku = df_sku.sort_values(\"PERIODO\")  # PERIODO j√° est√° AAAAMM\n",
    "    y = df_sku[\"QTD\"].values\n",
    "\n",
    "    # hist√≥rico curto\n",
    "    if len(y) < 3:\n",
    "        fc = np.ones(horizon) * np.mean(y)\n",
    "        return np.maximum(fc, 0)  # <<< TRAVA NEGATIVO\n",
    "\n",
    "    zero_rate = (y == 0).mean()\n",
    "    if zero_rate >= 0.40:\n",
    "        return croston(y, horizon)  # j√° retorna >= 0\n",
    "\n",
    "    try:\n",
    "        model = ExponentialSmoothing(y, trend=\"add\", seasonal=None)\n",
    "        fit = model.fit(optimized=True)\n",
    "        fc = fit.forecast(horizon)\n",
    "        return np.maximum(fc, 0)  # <<< TRAVA NEGATIVO\n",
    "    except:\n",
    "        fc = np.ones(horizon) * np.mean(y)\n",
    "        return np.maximum(fc, 0)  # <<< TRAVA NEGATIVO\n",
    "\n",
    "# ============================================================\n",
    "# PIPELINE COMPLETO ‚Äì Consumindo df_vendas_viqua direto\n",
    "# ============================================================\n",
    "\n",
    "def gerar_forecast_viqua_df(df_vendas_viqua):\n",
    "    print(\"üîÑ Usando PERIODO no formato AAAAMM...\")\n",
    "    df = df_vendas_viqua.copy()\n",
    "\n",
    "    df_group = (\n",
    "        df.groupby([\"COD_PROD\", \"PERIODO\"])\n",
    "          .agg(QTD=(\"QTD\", \"sum\"))\n",
    "          .reset_index()\n",
    "    )\n",
    "\n",
    "    df_group[\"QTD\"] = df_group.groupby(\"COD_PROD\")[\"QTD\"].transform(smooth_outliers)\n",
    "\n",
    "    print(\"üîÑ Criando calend√°rio futuro (Fev/26 ‚Üí Jul/26)...\")\n",
    "    future_periods = [\"202602\", \"202603\", \"202604\", \"202605\", \"202606\", \"202607\"]\n",
    "\n",
    "    registros = []\n",
    "\n",
    "    print(\"üîÑ Gerando previs√£o por SKU...\")\n",
    "    for sku, df_sku in df_group.groupby(\"COD_PROD\"):\n",
    "        fc = forecast_sku(df_sku, horizon=6)\n",
    "        for per, val in zip(future_periods, fc):\n",
    "            registros.append([sku, per, float(val)])\n",
    "\n",
    "    df_forecast = pd.DataFrame(registros, columns=[\"COD_PROD\", \"PERIODO\", \"FORECAST\"])\n",
    "\n",
    "    return df_forecast\n",
    "\n",
    "# ============================================================\n",
    "# EXECUTAR\n",
    "# ============================================================\n",
    "df_forecast_produto_periodo = gerar_forecast_viqua_df(df_vendas_viqua)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f7efa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Salvando df_forecast_viqua como Parquet...\n"
     ]
    }
   ],
   "source": [
    "# DESAGREGA√á√ÉO ESTATISTICA\n",
    "\n",
    "# Preparar hist√≥rico\n",
    "df_hist = df_vendas_viqua.copy()\n",
    "df_hist[\"PERIODO\"] = df_hist[\"PERIODO\"].astype(str)\n",
    "\n",
    "# Calcular participa√ß√£o hist√≥rica (chave completa: PRODUTO + REGIONAL + CLIENTE)\n",
    "df_part = (\n",
    "    df_hist.groupby([\"COD_PROD\", \"REGIONAL\", \"COD_CLIENTE\"])\n",
    "           .agg(QTD_HIST=(\"QTD\", \"sum\"))\n",
    "           .reset_index()\n",
    ")\n",
    "\n",
    "df_total_prod = (\n",
    "    df_part.groupby(\"COD_PROD\")[\"QTD_HIST\"]\n",
    "           .sum()\n",
    "           .reset_index()\n",
    "           .rename(columns={\"QTD_HIST\": \"TOTAL_PROD\"})\n",
    ")\n",
    "\n",
    "df_part = df_part.merge(df_total_prod, on=\"COD_PROD\", how=\"left\")\n",
    "df_part[\"PARTICIPACAO\"] = df_part[\"QTD_HIST\"] / df_part[\"TOTAL_PROD\"]\n",
    "df_part[\"PARTICIPACAO\"] = df_part[\"PARTICIPACAO\"].fillna(0)\n",
    "\n",
    "# Expandir forecast em uma √∫nica passada\n",
    "df_exp = df_forecast_produto_periodo.merge(df_part, on=\"COD_PROD\", how=\"left\")\n",
    "df_exp[\"FORECAST_DISTRIB\"] = df_exp[\"FORECAST\"] * df_exp[\"PARTICIPACAO\"]\n",
    "\n",
    "# Trazer atributos do produto e cliente (sem duplica√ß√£o)\n",
    "df_dim = (\n",
    "    df_hist[\n",
    "        [\n",
    "            \"COD_PROD\", \"DESC_PROD\", \"FAMILIA\", \"GRUPO_PROD\",\n",
    "            \"COD_CLIENTE\", \"NOM_CLIENTE\", \"REGIONAL\"\n",
    "        ]\n",
    "    ]\n",
    "    .drop_duplicates(subset=[\"COD_PROD\", \"COD_CLIENTE\", \"REGIONAL\"])\n",
    ")\n",
    "\n",
    "df_forecast_viqua = df_exp.merge(\n",
    "    df_dim,\n",
    "    on=[\"COD_PROD\", \"COD_CLIENTE\", \"REGIONAL\"],\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# Tabela final no formato padr√£o\n",
    "df_forecast_viqua = df_forecast_viqua[\n",
    "    [\n",
    "        \"COD_PROD\", \"DESC_PROD\", \"FAMILIA\", \"GRUPO_PROD\", \"COD_CLIENTE\",\n",
    "        \"NOM_CLIENTE\", \"REGIONAL\",\"FORECAST_DISTRIB\", \"PERIODO\"\n",
    "    ]\n",
    "].rename(columns={\"FORECAST_DISTRIB\": \"QTD\"})\n",
    "\n",
    "# Gerar arquivo Parquet\n",
    "nome_df = \"df_forecast_viqua\"\n",
    "print(f\"üíæ Salvando {nome_df} como Parquet...\")\n",
    "pl.from_pandas(df_forecast_viqua).write_parquet(pasta_staging_parquet / \"df_forecast_viqua.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed4e089",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Salvando df_forecast_venda_viqua como Parquet...\n",
      "‚úÖ Desagrega√ß√£o conclu√≠da com sucesso!\n"
     ]
    }
   ],
   "source": [
    "# Adicionar REGIONAL_GESTOR nos arquivos df_forecast_venda_viqua e df_vendas_viqua\n",
    "df_forecast_venda_viqua = df_forecast_viqua.merge(\n",
    "    df_regionais_gestor,\n",
    "    on=\"REGIONAL\",\n",
    "    how=\"left\",\n",
    "    suffixes=('', '_excluir')\n",
    ")\n",
    "\n",
    "# Excluir colunas com sufixo _excluir\n",
    "df_forecast_venda_viqua = df_forecast_venda_viqua[[col for col in df_forecast_venda_viqua.columns if not col.endswith('_excluir')]]\n",
    "\n",
    "df_vendas_viqua = df_vendas_viqua.merge(\n",
    "    df_regionais_gestor,\n",
    "    on=\"REGIONAL\",\n",
    "    how=\"left\",\n",
    "    suffixes=('', '_excluir')\n",
    ")\n",
    "\n",
    "# Excluir colunas com sufixo _excluir\n",
    "df_vendas_viqua = df_vendas_viqua[[col for col in df_vendas_viqua.columns if not col.endswith('_excluir')]]\n",
    "\n",
    "# Unificar df_vendas_viqua e df_forecast_viqua.parquet em um √∫nico arquivo Parquet, para carregar no POWER BI\n",
    "df_forecast_venda_viqua = pd.concat([df_vendas_viqua, df_forecast_viqua], ignore_index=True)\n",
    "\n",
    "# Gerar arquivo Parquet\n",
    "nome_df = \"df_forecast_venda_viqua\"\n",
    "print(f\"üíæ Salvando {nome_df} como Parquet...\")\n",
    "df_forecast_venda_viqua.to_parquet(pasta_staging_parquet / \"df_forecast_venda_viqua.parquet\")\n",
    "\n",
    "print(\"‚úÖ Desagrega√ß√£o conclu√≠da com sucesso!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "f8ac46d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>REGIONAL</th>\n",
       "      <th>REGIONAL_GESTOR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SANTA CATARINA 2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PARANA</td>\n",
       "      <td>SUL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RJ ES</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IRRIGACAO 2</td>\n",
       "      <td>IRRIGACAO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TELEVENDAS</td>\n",
       "      <td>TELEVENDAS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CONSTRUTORA 1</td>\n",
       "      <td>CONSTRUTORA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NORDESTE 2</td>\n",
       "      <td>NORDESTE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>IRRIGACAO 1</td>\n",
       "      <td>IRRIGACAO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SPC 1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>CENTRO OESTE</td>\n",
       "      <td>CO NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>SPI 1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>TV IRRIGACAO</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>NORTE</td>\n",
       "      <td>CO NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>NORDESTE 3</td>\n",
       "      <td>NORDESTE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>MINAS GERAIS</td>\n",
       "      <td>MINAS RJ/ES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>RIO GRANDE DO SUL</td>\n",
       "      <td>SUL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>SANTA CATARINA 1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>NORDESTE 1</td>\n",
       "      <td>NORDESTE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>COMEX</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>CONSTRUTORA 2</td>\n",
       "      <td>CONSTRUTORA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>SPC 2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>DIRETO ADM</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>SAC</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>SUPERVISOR TESTE</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>SP CAPITAL</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>CENTRO OESTE</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>CONSTRUTORA 1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>CONSTRUTORA 2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>IRRIGACAO 1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>IRRIGACAO 2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>MINAS GERAIS</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>NORDESTE 1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>NORDESTE 2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>NORDESTE 3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>NORTE</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>PARANA</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>RIO GRANDE DO SUL</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>TELEVENDAS</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             REGIONAL REGIONAL_GESTOR\n",
       "0    SANTA CATARINA 2             NaN\n",
       "1              PARANA             SUL\n",
       "2               RJ ES             NaN\n",
       "3         IRRIGACAO 2       IRRIGACAO\n",
       "4          TELEVENDAS      TELEVENDAS\n",
       "5       CONSTRUTORA 1     CONSTRUTORA\n",
       "6          NORDESTE 2        NORDESTE\n",
       "7         IRRIGACAO 1       IRRIGACAO\n",
       "8                None             NaN\n",
       "9               SPC 1             NaN\n",
       "10       CENTRO OESTE           CO NO\n",
       "11              SPI 1             NaN\n",
       "12       TV IRRIGACAO             NaN\n",
       "13              NORTE           CO NO\n",
       "14         NORDESTE 3        NORDESTE\n",
       "15       MINAS GERAIS     MINAS RJ/ES\n",
       "16  RIO GRANDE DO SUL             SUL\n",
       "17   SANTA CATARINA 1             NaN\n",
       "18         NORDESTE 1        NORDESTE\n",
       "19              COMEX             NaN\n",
       "20      CONSTRUTORA 2     CONSTRUTORA\n",
       "21              SPC 2             NaN\n",
       "22         DIRETO ADM             NaN\n",
       "23                SAC             NaN\n",
       "24   SUPERVISOR TESTE             NaN\n",
       "25         SP CAPITAL             NaN\n",
       "26       CENTRO OESTE             NaN\n",
       "27      CONSTRUTORA 1             NaN\n",
       "28      CONSTRUTORA 2             NaN\n",
       "29        IRRIGACAO 1             NaN\n",
       "30        IRRIGACAO 2             NaN\n",
       "31       MINAS GERAIS             NaN\n",
       "32         NORDESTE 1             NaN\n",
       "33         NORDESTE 2             NaN\n",
       "34         NORDESTE 3             NaN\n",
       "35              NORTE             NaN\n",
       "36             PARANA             NaN\n",
       "37  RIO GRANDE DO SUL             NaN\n",
       "38         TELEVENDAS             NaN"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Listar Regional e Regional_Gestor com base na df_forecast_venda_viqua\n",
    "df_avalia_regional_gestor_nan = df_forecast_venda_viqua[['REGIONAL', 'REGIONAL_GESTOR']].drop_duplicates().reset_index(drop=True)\n",
    "df_avalia_regional_gestor_nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "783186a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nPONTOS PENDENTES:\\n- Ver com Anna Regionais Gestor ficaram NAN\\n'"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "PONTOS PENDENTES:\n",
    "- Ver com Anna Regionais Gestor ficaram NAN\n",
    "- Ver as altera√ß√µes de nomes de pastas do diret√≥rio do projeto\n",
    "- Considerar para defini√ß√£o dos per√≠odos, a tabela nova nas regras de neg√≥cio\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "39d0623a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚è±Ô∏è Tempo total de processamento: 0 min 24.9 s\n",
      "üéØ Processo conclu√≠do com sucesso!\n"
     ]
    }
   ],
   "source": [
    "timer.finalizar()\n",
    "print(\"üéØ Processo conclu√≠do com sucesso!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3223f8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comando criar Requirements.txt\n",
    "# pip freeze > \".\\00_SCRIPTS\\requirements.txt\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
